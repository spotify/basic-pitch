{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "784208b9",
   "metadata": {},
   "source": [
    "# Custom Training Code <br>\n",
    "Built by Alex Fisher and Kevin Parra-Olmedo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c20eae",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eba1832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mir_eval\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pretty_midi\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../basic_pitch_original/')\n",
    "\n",
    "from basic_pitch import inference\n",
    "from basic_pitch import models\n",
    "\n",
    "from basic_pitch.constants import (\n",
    "    ANNOT_N_FRAMES,\n",
    "    ANNOTATIONS_FPS,\n",
    "    ANNOTATIONS_N_SEMITONES,\n",
    "    AUDIO_N_SAMPLES,\n",
    "    N_FREQ_BINS_CONTOURS,\n",
    "    AUDIO_SAMPLE_RATE,\n",
    "    FFT_HOP\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 3\n",
    "SPLIT_INTERVAL = 5\n",
    "\n",
    "tfkl = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e0af8dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/maestro/maestro-v3.0.0/maestro-v3.0.0.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\_AlexFiles\\Coding\\Python\\FALL2023_IndependentStudy\\audio_to_midi_vst\\independent_study\\Training.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Load in the ground truth MIDI files\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# glob is a pattern matching utility for files\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#use maestro-v3.0.0.json to get needed files\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# outdated code because I took a sample of the dataset and put in a different folder\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mdatasets/maestro/maestro-v3.0.0/maestro-v3.0.0.json\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     midi_filenames \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mmidi_filename\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/maestro/maestro-v3.0.0/maestro-v3.0.0.json'"
     ]
    }
   ],
   "source": [
    "# Load in the ground truth MIDI files\n",
    "# glob is a pattern matching utility for files\n",
    "\n",
    "#use maestro-v3.0.0.json to get needed files\n",
    "\n",
    "# outdated code because I took a sample of the dataset and put in a different folder\n",
    "\n",
    "with open('datasets/maestro/maestro-v3.0.0/maestro-v3.0.0.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    midi_filenames = data['midi_filename']\n",
    "    audio_filenames = data['audio_filename']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6d175e",
   "metadata": {},
   "source": [
    "## Load in sample dataset files<br>\n",
    "We are using a small sample from MAESTRO dataset's 100 GB of midi/wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e1b37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../datasets/maestro_sample\\\\MIDI-Unprocessed_Chamber2_MID--AUDIO_09_R3_2018_wav--1.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--1.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--2.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Chamber4_MID--AUDIO_11_R3_2018_wav--1.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Chamber5_MID--AUDIO_18_R3_2018_wav--1.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Chamber6_MID--AUDIO_20_R3_2018_wav--1.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Chamber6_MID--AUDIO_20_R3_2018_wav--2.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--1.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--2.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--3.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--4.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--1.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--2.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--3.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--4.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_03_R1_2018_wav--1.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_03_R1_2018_wav--2.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_03_R1_2018_wav--4.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_03_R1_2018_wav--5.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital4_MID--AUDIO_04_R1_2018_wav--1.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital4_MID--AUDIO_04_R1_2018_wav--3.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital4_MID--AUDIO_04_R1_2018_wav--4.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital4_MID--AUDIO_04_R1_2018_wav--5.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_05_R1_2018_wav--1.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_05_R1_2018_wav--2.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_05_R1_2018_wav--3.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_06_R1_2018_wav--1.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_06_R1_2018_wav--2.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_06_R1_2018_wav--3.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_07_R1_2018_wav--1.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_07_R1_2018_wav--2.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_07_R1_2018_wav--3.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_07_R1_2018_wav--4.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital8_MID--AUDIO_08_R1_2018_wav--1.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital8_MID--AUDIO_08_R1_2018_wav--2.midi', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital8_MID--AUDIO_08_R1_2018_wav--3.midi']\n",
      "['../../datasets/maestro_sample\\\\MIDI-Unprocessed_Chamber2_MID--AUDIO_09_R3_2018_wav--1.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--1.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--2.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Chamber4_MID--AUDIO_11_R3_2018_wav--1.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Chamber5_MID--AUDIO_18_R3_2018_wav--1.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Chamber6_MID--AUDIO_20_R3_2018_wav--1.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Chamber6_MID--AUDIO_20_R3_2018_wav--2.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--1.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--2.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--3.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--4.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--1.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--2.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--3.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--4.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_03_R1_2018_wav--1.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_03_R1_2018_wav--2.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_03_R1_2018_wav--4.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital1-3_MID--AUDIO_03_R1_2018_wav--5.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital4_MID--AUDIO_04_R1_2018_wav--1.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital4_MID--AUDIO_04_R1_2018_wav--3.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital4_MID--AUDIO_04_R1_2018_wav--4.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital4_MID--AUDIO_04_R1_2018_wav--5.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_05_R1_2018_wav--1.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_05_R1_2018_wav--2.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_05_R1_2018_wav--3.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_06_R1_2018_wav--1.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_06_R1_2018_wav--2.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_06_R1_2018_wav--3.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_07_R1_2018_wav--1.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_07_R1_2018_wav--2.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_07_R1_2018_wav--3.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital5-7_MID--AUDIO_07_R1_2018_wav--4.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital8_MID--AUDIO_08_R1_2018_wav--1.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital8_MID--AUDIO_08_R1_2018_wav--2.wav', '../../datasets/maestro_sample\\\\MIDI-Unprocessed_Recital8_MID--AUDIO_08_R1_2018_wav--3.wav']\n",
      "36\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "# get maestro sample files\n",
    "\n",
    "midi_filenames = glob.glob('../../datasets/maestro_sample/*.midi')\n",
    "audio_filenames = glob.glob('../../datasets/maestro_sample/*.wav')\n",
    "\n",
    "print(midi_filenames)\n",
    "print(audio_filenames)\n",
    "\n",
    "print(len(midi_filenames))\n",
    "print(len(audio_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026d478e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c586f7d",
   "metadata": {},
   "source": [
    "# Preprocess audio and MIDI pair files\n",
    "Audio needs to fit what model takes as input (windowed audio, uses Basic Pitch's inference get_audio_input function)<br>\n",
    "MIDI needs to match what model outputs (binary matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2070e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_piano_onset_matrix(midi_path, frames_per_second=ANNOTATIONS_FPS):\n",
    "    \"\"\"\n",
    "    Convert MIDI file to a binary matrix representing onset of piano keys using a set FPS.\n",
    "\n",
    "    Parameters:\n",
    "    - midi_path (str): Path to the MIDI file.\n",
    "    - frames_per_second (int): Number of frames per second for the binary representation.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: Binary matrix where rows represent the 88 piano keys and columns are time frames.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the MIDI file\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
    "\n",
    "    # Duration of the MIDI file in seconds\n",
    "    duration = midi_data.get_end_time()\n",
    "\n",
    "    # 88 keys for standard piano\n",
    "    num_piano_keys = 88\n",
    "\n",
    "    # Calculate the total number of frames based on the FPS\n",
    "    total_frames = int(duration * frames_per_second)\n",
    "\n",
    "    # Initialize binary matrix with zeros\n",
    "    binary_matrix = np.zeros((total_frames, num_piano_keys))\n",
    "\n",
    "    for instrument in midi_data.instruments:\n",
    "        for note in instrument.notes:\n",
    "            # Only consider valid piano notes (from 21 to 108)\n",
    "            if 21 <= note.pitch <= 108:\n",
    "                # Find the frame for this onset time\n",
    "                onset_frame = int(note.start * frames_per_second)\n",
    "\n",
    "                # Prevent indexing beyond the matrix size\n",
    "                if onset_frame < total_frames:\n",
    "                    # Adjust the pitch value to fit within our matrix's row indices (0-87)\n",
    "                    adjusted_pitch = note.pitch - 21\n",
    "\n",
    "                    # Mark the onset in the binary matrix\n",
    "                    binary_matrix[onset_frame, adjusted_pitch] = 1\n",
    "\n",
    "    return binary_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3778e277",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\_AlexFiles\\Coding\\Python\\FALL2023_IndependentStudy\\audio_to_midi_vst\\independent_study\\Training.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m x\u001b[39m.\u001b[39mappend(audio_windowed)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# preprocess midi\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m pm_midi \u001b[39m=\u001b[39m pretty_midi\u001b[39m.\u001b[39;49mPrettyMIDI(midi_filenames[idx])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m onsets \u001b[39m=\u001b[39m midi_to_piano_onset_matrix(midi_filenames[idx], frames_per_second\u001b[39m=\u001b[39mANNOTATIONS_FPS)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m y\u001b[39m.\u001b[39mappend(onsets)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\pretty_midi\\pretty_midi.py:63\u001b[0m, in \u001b[0;36mPrettyMIDI.__init__\u001b[1;34m(self, midi_file, resolution, initial_tempo)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mif\u001b[39;00m midi_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     \u001b[39m# Load in the MIDI data using the midi module\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(midi_file, six\u001b[39m.\u001b[39mstring_types):\n\u001b[0;32m     62\u001b[0m         \u001b[39m# If a string was given, pass it as the string filename\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m         midi_data \u001b[39m=\u001b[39m mido\u001b[39m.\u001b[39;49mMidiFile(filename\u001b[39m=\u001b[39;49mmidi_file)\n\u001b[0;32m     64\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m         \u001b[39m# Otherwise, try passing it in as a file pointer\u001b[39;00m\n\u001b[0;32m     66\u001b[0m         midi_data \u001b[39m=\u001b[39m mido\u001b[39m.\u001b[39mMidiFile(file\u001b[39m=\u001b[39mmidi_file)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\mido\\midifiles\\midifiles.py:325\u001b[0m, in \u001b[0;36mMidiFile.__init__\u001b[1;34m(self, filename, file, type, ticks_per_beat, charset, debug, clip, tracks)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[39m# merge tracks at load time to prevent timing error on\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[39m# first call to __iter__()\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m--> 325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmerged_track \u001b[39m=\u001b[39m merge_tracks(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtracks)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\mido\\midifiles\\tracks.py:118\u001b[0m, in \u001b[0;36mmerge_tracks\u001b[1;34m(tracks)\u001b[0m\n\u001b[0;32m    114\u001b[0m     messages\u001b[39m.\u001b[39mextend(_to_abstime(track))\n\u001b[0;32m    116\u001b[0m messages\u001b[39m.\u001b[39msort(key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m msg: msg\u001b[39m.\u001b[39mtime)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m MidiTrack(fix_end_of_track(_to_reltime(messages)))\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\mido\\midifiles\\tracks.py:92\u001b[0m, in \u001b[0;36mfix_end_of_track\u001b[1;34m(messages)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39m# Accumulated delta time from removed end of track messages.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[39m# This is added to the next message.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m accum \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 92\u001b[0m \u001b[39mfor\u001b[39;00m msg \u001b[39min\u001b[39;00m messages:\n\u001b[0;32m     93\u001b[0m     \u001b[39mif\u001b[39;00m msg\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend_of_track\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     94\u001b[0m         accum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m msg\u001b[39m.\u001b[39mtime\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\mido\\midifiles\\tracks.py:80\u001b[0m, in \u001b[0;36m_to_reltime\u001b[1;34m(messages)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mfor\u001b[39;00m msg \u001b[39min\u001b[39;00m messages:\n\u001b[0;32m     79\u001b[0m     delta \u001b[39m=\u001b[39m msg\u001b[39m.\u001b[39mtime \u001b[39m-\u001b[39m now\n\u001b[1;32m---> 80\u001b[0m     \u001b[39myield\u001b[39;00m msg\u001b[39m.\u001b[39;49mcopy(time\u001b[39m=\u001b[39;49mdelta)\n\u001b[0;32m     81\u001b[0m     now \u001b[39m=\u001b[39m msg\u001b[39m.\u001b[39mtime\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\mido\\messages\\messages.py:143\u001b[0m, in \u001b[0;36mMessage.copy\u001b[1;34m(self, **overrides)\u001b[0m\n\u001b[0;32m    141\u001b[0m msgdict\u001b[39m.\u001b[39mupdate(overrides)\n\u001b[0;32m    142\u001b[0m check_msgdict(msgdict)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmsgdict)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\mido\\messages\\messages.py:118\u001b[0m, in \u001b[0;36mMessage.__init__\u001b[1;34m(self, type, **args)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msysex\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    117\u001b[0m     msgdict[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m SysexData(msgdict[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 118\u001b[0m check_msgdict(msgdict)\n\u001b[0;32m    119\u001b[0m \u001b[39mvars\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mupdate(msgdict)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\mido\\messages\\checks.py:102\u001b[0m, in \u001b[0;36mcheck_msgdict\u001b[1;34m(msgdict)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m spec[\u001b[39m'\u001b[39m\u001b[39mattribute_names\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     99\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    100\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m message has no attribute \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(spec[\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m], name))\n\u001b[1;32m--> 102\u001b[0m check_value(name, value)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for idx in range(0, int(len(audio_filenames))):\n",
    "\n",
    "    # preprocess audio\n",
    "    n_overlapping_frames = 30\n",
    "    overlap_len = n_overlapping_frames * FFT_HOP\n",
    "    hop_size = AUDIO_N_SAMPLES - overlap_len\n",
    "    audio_windowed, _, audio_original_length = inference.get_audio_input(audio_filenames[idx], overlap_len, hop_size)\n",
    "\n",
    "    x.append(audio_windowed)\n",
    "\n",
    "    # preprocess midi\n",
    "    pm_midi = pretty_midi.PrettyMIDI(midi_filenames[idx])\n",
    "    onsets = midi_to_piano_onset_matrix(midi_filenames[idx], frames_per_second=ANNOTATIONS_FPS)\n",
    "    y.append(onsets)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "834e9ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one song dataset\n",
    "\n",
    "os_x = []\n",
    "orig_audio_len = []\n",
    "os_y = []\n",
    "\n",
    "for idx in range(0, int(len(audio_filenames))):\n",
    "    offset = 0\n",
    "    # preprocess midi\n",
    "    onsets = midi_to_piano_onset_matrix(midi_filenames[idx], frames_per_second=ANNOTATIONS_FPS)\n",
    "    while offset < librosa.get_duration(path=audio_filenames[idx]) - SPLIT_INTERVAL:\n",
    "        # preprocess audio\n",
    "\n",
    "        n_overlapping_frames = 30\n",
    "        overlap_len = n_overlapping_frames * FFT_HOP\n",
    "        hop_size = AUDIO_N_SAMPLES - overlap_len\n",
    "\n",
    "        # modified get_input_audio function to get audio from offset\n",
    "        assert overlap_len % 2 == 0, \"overlap_length must be even, got {}\".format(overlap_len)\n",
    "        audio_original, _ = librosa.load(audio_filenames[idx], sr=AUDIO_SAMPLE_RATE, offset=offset, duration=SPLIT_INTERVAL, mono=True)\n",
    "\n",
    "        original_length = audio_original.shape[0]\n",
    "        audio_original = np.concatenate([np.zeros((int(overlap_len / 2),), dtype=np.float32), audio_original])\n",
    "        audio_windowed, window_times = inference.window_audio_file(audio_original, hop_size)\n",
    "    \n",
    "        os_x.append(audio_windowed)\n",
    "        orig_audio_len.append(original_length)\n",
    "\n",
    "        split_onsets = onsets[int(offset*ANNOTATIONS_FPS):int((offset+SPLIT_INTERVAL)*ANNOTATIONS_FPS), :]\n",
    "        if (split_onsets.shape[0] < ANNOTATIONS_FPS * SPLIT_INTERVAL):\n",
    "            padding = ANNOTATIONS_FPS * SPLIT_INTERVAL - split_onsets.shape[0]\n",
    "            split_onsets = np.pad(split_onsets, [(0, padding), (0, 0)], 'constant')\n",
    "        os_y.append(split_onsets)\n",
    "\n",
    "        offset += SPLIT_INTERVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c8b62a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 43844, 1)\n",
      "(430, 88)\n",
      "7257\n",
      "7257\n",
      "7257\n",
      "tf.Tensor(\n",
      "[[[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  ...\n",
      "  [-0.0117997 ]\n",
      "  [-0.01149738]\n",
      "  [-0.01084852]]\n",
      "\n",
      " [[ 0.00116504]\n",
      "  [ 0.00040939]\n",
      "  [-0.00011012]\n",
      "  ...\n",
      "  [-0.03573342]\n",
      "  [-0.03855322]\n",
      "  [-0.03870913]]\n",
      "\n",
      " [[ 0.00629463]\n",
      "  [ 0.0067053 ]\n",
      "  [ 0.00703699]\n",
      "  ...\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[-0.01862951]\n",
      "  [-0.01724252]\n",
      "  [-0.01553928]\n",
      "  ...\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]], shape=(4, 43844, 1), dtype=float32)\n",
      "110250\n"
     ]
    }
   ],
   "source": [
    "print(os_x[0].shape)\n",
    "print(os_y[0].shape)\n",
    "\n",
    "print(len(os_x))\n",
    "print(len(os_y))\n",
    "print(len(orig_audio_len))\n",
    "\n",
    "print(os_x[0])\n",
    "print(orig_audio_len[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4570083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT BATCH DATASET \n",
    "\n",
    "tensor_dataset = tf.data.Dataset.from_tensor_slices((os_x, os_y))\n",
    "#tensor_dataset = tensor_dataset.take(300) # take 300 batches for now, comment this out later\n",
    "train_dataset = tensor_dataset.take(int(len(tensor_dataset)*0.8))\n",
    "val_dataset = tensor_dataset.skip(int(len(tensor_dataset)*0.8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f58ab849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset:  <_TakeDataset element_spec=(TensorSpec(shape=(4, 43844, 1), dtype=tf.float32, name=None), TensorSpec(shape=(430, 88), dtype=tf.float64, name=None))>\n",
      "val_dataset:  <_SkipDataset element_spec=(TensorSpec(shape=(4, 43844, 1), dtype=tf.float32, name=None), TensorSpec(shape=(430, 88), dtype=tf.float64, name=None))>\n",
      "Size of take_dataset: 240\n",
      "Size of skip_dataset: 60\n",
      "Size of batched_dataset: 300\n"
     ]
    }
   ],
   "source": [
    "print(\"train_dataset: \", train_dataset)\n",
    "print(\"val_dataset: \", val_dataset)\n",
    "\n",
    "take_count = sum(1 for _ in train_dataset)\n",
    "print(f\"Size of take_dataset: {take_count}\")\n",
    "\n",
    "skip_count = sum(1 for _ in val_dataset)\n",
    "print(f\"Size of skip_dataset: {skip_count}\")\n",
    "\n",
    "ds_count = sum(1 for _ in tensor_dataset)\n",
    "print(f\"Size of batched_dataset: {ds_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382b17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put data into batches\n",
    "batched_dataset = []\n",
    "batch_size = 1 # change this to BATCH_SIZE later\n",
    "\n",
    "i = 0\n",
    "while (i < len(x)):\n",
    "    if (i < len(x) - batch_size):\n",
    "        x_batch = x[i:i+batch_size]\n",
    "        y_batch = y[i:i+batch_size]\n",
    "        batched_dataset.append((x_batch, y_batch))\n",
    "    else:\n",
    "        x_batch = x[i:]\n",
    "        y_batch = y[i:]\n",
    "        batched_dataset.append((x_batch, y_batch))\n",
    "    i += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c037db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split batched dataset into training and validation sets\n",
    "# 80% training, 20% validation\n",
    "train_dataset = batched_dataset[:int(len(batched_dataset)*0.8)]\n",
    "val_dataset = batched_dataset[int(len(batched_dataset)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31589e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train/test split\n",
    "# 80% training, 20% validation\n",
    "x_train = x[:int(len(x)*0.8)]\n",
    "y_train = y[:int(len(y)*0.8)]\n",
    "x_test = x[int(len(x)*0.8):]\n",
    "y_test = y[int(len(y)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a8efcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 6s 288ms/step\n"
     ]
    }
   ],
   "source": [
    "output = model.predict(x_test[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37ffa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize spotify basic pitch model\n",
    "model = models.model()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Initialize the model\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_function = tf.keras.losses.BinaryCrossentropy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559da772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'onset': <tf.Tensor: shape=(356, 172, 88), dtype=float32, numpy=\n",
      "array([[[0.04727691, 0.08470501, 0.0437418 , ..., 0.02655039,\n",
      "         0.02690475, 0.03086778],\n",
      "        [0.05278471, 0.03867819, 0.00993544, ..., 0.04313786,\n",
      "         0.01514172, 0.0203534 ],\n",
      "        [0.26405764, 0.5626659 , 0.17359261, ..., 0.03620816,\n",
      "         0.01413448, 0.0142984 ],\n",
      "        ...,\n",
      "        [0.1899556 , 0.43211785, 0.5669065 , ..., 0.10389652,\n",
      "         0.05054878, 0.05620126],\n",
      "        [0.24860631, 0.3420169 , 0.44899505, ..., 0.13852572,\n",
      "         0.08319806, 0.09333236],\n",
      "        [0.3292999 , 0.53262085, 0.60701287, ..., 0.2194675 ,\n",
      "         0.14628221, 0.21946846]],\n",
      "\n",
      "       [[0.3681499 , 0.32686046, 0.44428867, ..., 0.05431946,\n",
      "         0.05742459, 0.07718755],\n",
      "        [0.27146247, 0.54407746, 0.6061005 , ..., 0.11466714,\n",
      "         0.04711415, 0.07696318],\n",
      "        [0.38571095, 0.42635372, 0.5341912 , ..., 0.09636305,\n",
      "         0.04582022, 0.05597818],\n",
      "        ...,\n",
      "        [0.34633774, 0.22532123, 0.44289908, ..., 0.10719749,\n",
      "         0.06982382, 0.08258094],\n",
      "        [0.3102027 , 0.20048983, 0.58820266, ..., 0.2119723 ,\n",
      "         0.10306786, 0.12067379],\n",
      "        [0.39506766, 0.4177386 , 0.56590503, ..., 0.4956919 ,\n",
      "         0.25628352, 0.24990596]],\n",
      "\n",
      "       [[0.39331636, 0.3021737 , 0.29265302, ..., 0.076336  ,\n",
      "         0.06467905, 0.08592016],\n",
      "        [0.4217033 , 0.31833953, 0.41694996, ..., 0.10847264,\n",
      "         0.07412875, 0.09679668],\n",
      "        [0.3564447 , 0.31926566, 0.41436794, ..., 0.08634207,\n",
      "         0.05477669, 0.06120106],\n",
      "        ...,\n",
      "        [0.41801643, 0.36895564, 0.47054464, ..., 0.2879379 ,\n",
      "         0.15835771, 0.25409397],\n",
      "        [0.39336294, 0.30912793, 0.39373228, ..., 0.17555256,\n",
      "         0.14425793, 0.25384805],\n",
      "        [0.45224053, 0.55767316, 0.5347553 , ..., 0.26370442,\n",
      "         0.19445463, 0.40503022]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.4916406 , 0.15595652, 0.4401604 , ..., 0.23723803,\n",
      "         0.2281934 , 0.25278568],\n",
      "        [0.6373873 , 0.28571767, 0.53537536, ..., 0.31471068,\n",
      "         0.32726052, 0.30037642],\n",
      "        [0.6267863 , 0.15079801, 0.45889845, ..., 0.2661054 ,\n",
      "         0.2695557 , 0.330659  ],\n",
      "        ...,\n",
      "        [0.4017533 , 0.25680533, 0.42327568, ..., 0.28315654,\n",
      "         0.12742375, 0.21580927],\n",
      "        [0.251028  , 0.2422911 , 0.32190633, ..., 0.25145078,\n",
      "         0.15757652, 0.24745062],\n",
      "        [0.48827457, 0.47482294, 0.48116657, ..., 0.31005687,\n",
      "         0.178593  , 0.29434878]],\n",
      "\n",
      "       [[0.55952615, 0.25438857, 0.534892  , ..., 0.1478813 ,\n",
      "         0.1384719 , 0.10139342],\n",
      "        [0.29233906, 0.33758628, 0.696679  , ..., 0.28388107,\n",
      "         0.12734285, 0.2280848 ],\n",
      "        [0.35202223, 0.2692121 , 0.46681172, ..., 0.2172642 ,\n",
      "         0.16980423, 0.19918822],\n",
      "        ...,\n",
      "        [0.4362324 , 0.4969197 , 0.26035535, ..., 0.1528931 ,\n",
      "         0.1621337 , 0.12812728],\n",
      "        [0.37617746, 0.5774951 , 0.26631916, ..., 0.24258842,\n",
      "         0.1135831 , 0.16728567],\n",
      "        [0.38655216, 0.67721033, 0.36020234, ..., 0.28024885,\n",
      "         0.20596647, 0.3027053 ]],\n",
      "\n",
      "       [[0.60362715, 0.33166814, 0.3559718 , ..., 0.23491742,\n",
      "         0.20862144, 0.25095585],\n",
      "        [0.4825383 , 0.31138745, 0.5157087 , ..., 0.2027289 ,\n",
      "         0.33326977, 0.23486793],\n",
      "        [0.4403418 , 0.24191904, 0.32817253, ..., 0.19057167,\n",
      "         0.22929019, 0.30167392],\n",
      "        ...,\n",
      "        [0.03398209, 0.18436098, 0.2751842 , ..., 0.03239528,\n",
      "         0.01597052, 0.01228234],\n",
      "        [0.05583613, 0.21388367, 0.30309805, ..., 0.01961385,\n",
      "         0.01778775, 0.02976088],\n",
      "        [0.18276086, 0.18708591, 0.40241987, ..., 0.04800455,\n",
      "         0.04426441, 0.09719022]]], dtype=float32)>, 'contour': <tf.Tensor: shape=(356, 172, 264), dtype=float32, numpy=\n",
      "array([[[0.46174943, 0.40085265, 0.4303734 , ..., 0.46260092,\n",
      "         0.48045495, 0.3973006 ],\n",
      "        [0.4579025 , 0.54878646, 0.6855606 , ..., 0.4760063 ,\n",
      "         0.5166024 , 0.39113176],\n",
      "        [0.71090513, 0.78995067, 0.7568192 , ..., 0.4705688 ,\n",
      "         0.50512946, 0.3799781 ],\n",
      "        ...,\n",
      "        [0.3441861 , 0.36357793, 0.35370904, ..., 0.45029217,\n",
      "         0.44988394, 0.49876893],\n",
      "        [0.3444732 , 0.36984932, 0.3392494 , ..., 0.4865739 ,\n",
      "         0.4681563 , 0.5118872 ],\n",
      "        [0.35754862, 0.385714  , 0.35085118, ..., 0.50455475,\n",
      "         0.5348011 , 0.5141163 ]],\n",
      "\n",
      "       [[0.3633546 , 0.47526988, 0.4511493 , ..., 0.45444316,\n",
      "         0.44648558, 0.42137086],\n",
      "        [0.36542583, 0.5015073 , 0.48331314, ..., 0.47313097,\n",
      "         0.50274825, 0.43147588],\n",
      "        [0.3381953 , 0.5140214 , 0.42764854, ..., 0.43744168,\n",
      "         0.4495787 , 0.3795428 ],\n",
      "        ...,\n",
      "        [0.42951804, 0.49048832, 0.6536555 , ..., 0.46027094,\n",
      "         0.47544312, 0.4303772 ],\n",
      "        [0.40472615, 0.51634055, 0.5880164 , ..., 0.5357679 ,\n",
      "         0.5844978 , 0.49452147],\n",
      "        [0.44423673, 0.5231299 , 0.59347445, ..., 0.50424236,\n",
      "         0.56267357, 0.5175223 ]],\n",
      "\n",
      "       [[0.37037292, 0.3962482 , 0.42064762, ..., 0.48227873,\n",
      "         0.4201644 , 0.41043788],\n",
      "        [0.3955725 , 0.393667  , 0.42969584, ..., 0.51862097,\n",
      "         0.47559854, 0.4412073 ],\n",
      "        [0.3520727 , 0.36950538, 0.37634334, ..., 0.48323095,\n",
      "         0.48309785, 0.43776783],\n",
      "        ...,\n",
      "        [0.3223663 , 0.24152832, 0.2332299 , ..., 0.69045895,\n",
      "         0.5207511 , 0.49843535],\n",
      "        [0.3557257 , 0.28180668, 0.2612425 , ..., 0.6154296 ,\n",
      "         0.54125404, 0.48302558],\n",
      "        [0.4008966 , 0.29849505, 0.29076108, ..., 0.62958825,\n",
      "         0.5766531 , 0.5458376 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.34860507, 0.24145557, 0.3147519 , ..., 0.4263741 ,\n",
      "         0.45801577, 0.49714798],\n",
      "        [0.3460184 , 0.24580842, 0.34246847, ..., 0.43332133,\n",
      "         0.39043117, 0.46095133],\n",
      "        [0.37905368, 0.23215392, 0.2937316 , ..., 0.4575298 ,\n",
      "         0.3961278 , 0.5221219 ],\n",
      "        ...,\n",
      "        [0.23287004, 0.37751883, 0.25768277, ..., 0.50460756,\n",
      "         0.53676593, 0.4503792 ],\n",
      "        [0.30313045, 0.45898214, 0.30250317, ..., 0.5263561 ,\n",
      "         0.48849797, 0.5037728 ],\n",
      "        [0.3211827 , 0.41334113, 0.33429378, ..., 0.55127436,\n",
      "         0.5898429 , 0.54487115]],\n",
      "\n",
      "       [[0.37981793, 0.29552594, 0.2850807 , ..., 0.45929122,\n",
      "         0.4643469 , 0.44567046],\n",
      "        [0.42046008, 0.30636254, 0.3547874 , ..., 0.3846453 ,\n",
      "         0.50502616, 0.4609121 ],\n",
      "        [0.33471334, 0.28766683, 0.28051913, ..., 0.37873653,\n",
      "         0.5065089 , 0.46690714],\n",
      "        ...,\n",
      "        [0.25333008, 0.22419304, 0.1427942 , ..., 0.6504644 ,\n",
      "         0.5529657 , 0.46692365],\n",
      "        [0.32807687, 0.34070528, 0.1675957 , ..., 0.66412485,\n",
      "         0.5633894 , 0.5249921 ],\n",
      "        [0.3962354 , 0.3140301 , 0.24696194, ..., 0.57189214,\n",
      "         0.5442054 , 0.55764467]],\n",
      "\n",
      "       [[0.30300638, 0.16676354, 0.18172878, ..., 0.40230903,\n",
      "         0.48635048, 0.45715383],\n",
      "        [0.25353152, 0.15773568, 0.12622559, ..., 0.44364196,\n",
      "         0.44307527, 0.43919095],\n",
      "        [0.21956058, 0.20755932, 0.10052475, ..., 0.52296513,\n",
      "         0.4240925 , 0.49509707],\n",
      "        ...,\n",
      "        [0.64907247, 0.6135559 , 0.4512983 , ..., 0.5211321 ,\n",
      "         0.5267841 , 0.41120675],\n",
      "        [0.64579225, 0.6603132 , 0.59702045, ..., 0.5392027 ,\n",
      "         0.53154564, 0.4522682 ],\n",
      "        [0.60556334, 0.6507062 , 0.62707925, ..., 0.5419645 ,\n",
      "         0.55355823, 0.5038149 ]]], dtype=float32)>, 'note': <tf.Tensor: shape=(356, 172, 88), dtype=float32, numpy=\n",
      "array([[[0.46501198, 0.44294685, 0.45431456, ..., 0.4836017 ,\n",
      "         0.48886606, 0.47141063],\n",
      "        [0.47323015, 0.45526496, 0.4700302 , ..., 0.4883202 ,\n",
      "         0.50308603, 0.4697608 ],\n",
      "        [0.49154204, 0.4852449 , 0.51827806, ..., 0.5033425 ,\n",
      "         0.5246528 , 0.48190925],\n",
      "        ...,\n",
      "        [0.5145382 , 0.48839307, 0.5013884 , ..., 0.49660942,\n",
      "         0.5112377 , 0.48147923],\n",
      "        [0.5336644 , 0.5150131 , 0.5325923 , ..., 0.531755  ,\n",
      "         0.54415697, 0.49934608],\n",
      "        [0.5250728 , 0.51001346, 0.5293039 , ..., 0.52367866,\n",
      "         0.5303341 , 0.49217537]],\n",
      "\n",
      "       [[0.48675758, 0.47237527, 0.49207202, ..., 0.48405716,\n",
      "         0.48133546, 0.4717632 ],\n",
      "        [0.4863738 , 0.4729588 , 0.50799924, ..., 0.48643228,\n",
      "         0.49421936, 0.4742865 ],\n",
      "        [0.5019952 , 0.4887128 , 0.52416795, ..., 0.5078058 ,\n",
      "         0.51914746, 0.48713642],\n",
      "        ...,\n",
      "        [0.51801264, 0.47411647, 0.517083  , ..., 0.49454126,\n",
      "         0.51553696, 0.48268244],\n",
      "        [0.5469633 , 0.5152685 , 0.5504593 , ..., 0.53396297,\n",
      "         0.5453816 , 0.4988424 ],\n",
      "        [0.5350193 , 0.5065955 , 0.5410017 , ..., 0.52652663,\n",
      "         0.5307241 , 0.48944166]],\n",
      "\n",
      "       [[0.49204043, 0.4780383 , 0.4916568 , ..., 0.48328915,\n",
      "         0.4825772 , 0.4722054 ],\n",
      "        [0.49339458, 0.48501953, 0.49826926, ..., 0.48950422,\n",
      "         0.49133825, 0.47001785],\n",
      "        [0.5013324 , 0.5003723 , 0.5314843 , ..., 0.50650656,\n",
      "         0.51500964, 0.48020035],\n",
      "        ...,\n",
      "        [0.51314086, 0.49204698, 0.4801775 , ..., 0.49225545,\n",
      "         0.51822513, 0.4729216 ],\n",
      "        [0.5306529 , 0.51849425, 0.5159897 , ..., 0.5354273 ,\n",
      "         0.5534291 , 0.49412963],\n",
      "        [0.52148825, 0.5175653 , 0.5157455 , ..., 0.5249166 ,\n",
      "         0.54198045, 0.49213162]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.49278918, 0.47450194, 0.49108157, ..., 0.4760596 ,\n",
      "         0.4611318 , 0.47622514],\n",
      "        [0.50011116, 0.47654322, 0.49528864, ..., 0.48194638,\n",
      "         0.478573  , 0.4705057 ],\n",
      "        [0.5023904 , 0.48222232, 0.50940377, ..., 0.50874156,\n",
      "         0.49880716, 0.48905632],\n",
      "        ...,\n",
      "        [0.5146645 , 0.4859543 , 0.5007899 , ..., 0.4988695 ,\n",
      "         0.5300671 , 0.48280284],\n",
      "        [0.5307178 , 0.5091036 , 0.51111484, ..., 0.53131735,\n",
      "         0.5533335 , 0.50123346],\n",
      "        [0.5250682 , 0.5078727 , 0.5021149 , ..., 0.5270669 ,\n",
      "         0.539995  , 0.4924138 ]],\n",
      "\n",
      "       [[0.49170503, 0.47690997, 0.4876627 , ..., 0.47393817,\n",
      "         0.47285947, 0.4801045 ],\n",
      "        [0.49539977, 0.48361638, 0.49667025, ..., 0.48302585,\n",
      "         0.5039205 , 0.47439277],\n",
      "        [0.49819756, 0.4921918 , 0.50854105, ..., 0.50549346,\n",
      "         0.5135952 , 0.492081  ],\n",
      "        ...,\n",
      "        [0.5059789 , 0.48894778, 0.4879537 , ..., 0.50461864,\n",
      "         0.5252918 , 0.47659233],\n",
      "        [0.5218328 , 0.51379234, 0.51424485, ..., 0.54086757,\n",
      "         0.5579977 , 0.4909338 ],\n",
      "        [0.5185006 , 0.5185935 , 0.5082399 , ..., 0.5395251 ,\n",
      "         0.54004997, 0.48796824]],\n",
      "\n",
      "       [[0.49455118, 0.48332363, 0.49346918, ..., 0.47132474,\n",
      "         0.46342197, 0.4730766 ],\n",
      "        [0.4987562 , 0.48377362, 0.4959405 , ..., 0.49189392,\n",
      "         0.4785707 , 0.47002506],\n",
      "        [0.49780118, 0.48980334, 0.5054388 , ..., 0.5173517 ,\n",
      "         0.50817865, 0.4846757 ],\n",
      "        ...,\n",
      "        [0.5223901 , 0.48807085, 0.4963492 , ..., 0.4913739 ,\n",
      "         0.51685494, 0.4815885 ],\n",
      "        [0.56289977, 0.55312127, 0.56552786, ..., 0.5273726 ,\n",
      "         0.54427123, 0.49904063],\n",
      "        [0.5483419 , 0.54034525, 0.5469284 , ..., 0.5273397 ,\n",
      "         0.5334535 , 0.49652016]]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "logits = model(train_dataset[0][0], training=True)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6110ce8d",
   "metadata": {},
   "source": [
    "## Train the model using the preprocessed data<br>\n",
    "Something unique about this training process is that the y_batch data must be further preprocessed by adding padding to match the shape of the matrix produced by the model's output so that the shapes match and can be directly compared in the loss function. <br>\n",
    "\n",
    "\n",
    "Not sure if there is a workaround for this. The only thing I can think of that might allow us to preprocess the data completely before the model predicts anything is by figuring out what matrix shape the model will produce before it produces it, then adding the padding to the MIDI matrix to match the shape. This might be able to be done by using some sort of equation with the input audio data. Model output always seems to produce more note onset information than is stored in the midi file. This could mean that the audio files need to be trimmed, but I'm not sure in what way or how to determine that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10ae0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae9c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: input_24\n",
      "Trainable: True\n",
      "Layer: flatten_audio_ch_23\n",
      "Trainable: True\n",
      "Layer: cqt2010v2_23\n",
      "Trainable: False\n",
      "Layer: normalized_log_23\n",
      "Trainable: True\n",
      "Layer: tf.expand_dims_46\n",
      "Trainable: True\n",
      "Layer: batch_normalization_92\n",
      "Trainable: True\n",
      "\tWeight: batch_normalization_92/gamma:0, Shape: (1,)\n",
      "\tWeight: batch_normalization_92/beta:0, Shape: (1,)\n",
      "Layer: harmonic_stacking\n",
      "Trainable: False\n",
      "Layer: conv2d_139\n",
      "Trainable: True\n",
      "\tWeight: conv2d_139/kernel:0, Shape: (3, 39, 8, 8)\n",
      "\tWeight: conv2d_139/bias:0, Shape: (8,)\n",
      "Layer: batch_normalization_94\n",
      "Trainable: True\n",
      "\tWeight: batch_normalization_94/gamma:0, Shape: (8,)\n",
      "\tWeight: batch_normalization_94/beta:0, Shape: (8,)\n",
      "Layer: re_lu_93\n",
      "Trainable: True\n",
      "Layer: contours-reduced\n",
      "Trainable: True\n",
      "\tWeight: contours-reduced/kernel:0, Shape: (5, 5, 8, 1)\n",
      "\tWeight: contours-reduced/bias:0, Shape: (1,)\n",
      "Layer: contour\n",
      "Trainable: True\n",
      "Layer: tf.expand_dims_47\n",
      "Trainable: True\n",
      "Layer: conv2d_140\n",
      "Trainable: True\n",
      "\tWeight: conv2d_140/kernel:0, Shape: (7, 7, 1, 32)\n",
      "\tWeight: conv2d_140/bias:0, Shape: (32,)\n",
      "Layer: conv2d_142\n",
      "Trainable: True\n",
      "\tWeight: conv2d_142/kernel:0, Shape: (5, 5, 8, 32)\n",
      "\tWeight: conv2d_142/bias:0, Shape: (32,)\n",
      "Layer: re_lu_94\n",
      "Trainable: True\n",
      "Layer: batch_normalization_95\n",
      "Trainable: True\n",
      "\tWeight: batch_normalization_95/gamma:0, Shape: (32,)\n",
      "\tWeight: batch_normalization_95/beta:0, Shape: (32,)\n",
      "Layer: conv2d_141\n",
      "Trainable: True\n",
      "\tWeight: conv2d_141/kernel:0, Shape: (7, 3, 32, 1)\n",
      "\tWeight: conv2d_141/bias:0, Shape: (1,)\n",
      "Layer: re_lu_95\n",
      "Trainable: True\n",
      "Layer: concat\n",
      "Trainable: True\n",
      "Layer: conv2d_143\n",
      "Trainable: True\n",
      "\tWeight: conv2d_143/kernel:0, Shape: (3, 3, 33, 1)\n",
      "\tWeight: conv2d_143/bias:0, Shape: (1,)\n",
      "Layer: note\n",
      "Trainable: True\n",
      "Layer: onset\n",
      "Trainable: True\n",
      "\n",
      "Only layers with trainable weights:\n",
      "Layer: batch_normalization_96\n",
      "\tWeight: batch_normalization_96/gamma:0, Shape: (1,)\n",
      "\tWeight: batch_normalization_96/beta:0, Shape: (1,)\n",
      "Layer: conv2d_145\n",
      "\tWeight: conv2d_145/kernel:0, Shape: (3, 39, 8, 8)\n",
      "\tWeight: conv2d_145/bias:0, Shape: (8,)\n",
      "Layer: batch_normalization_98\n",
      "\tWeight: batch_normalization_98/gamma:0, Shape: (8,)\n",
      "\tWeight: batch_normalization_98/beta:0, Shape: (8,)\n",
      "Layer: contours-reduced\n",
      "\tWeight: contours-reduced/kernel:0, Shape: (5, 5, 8, 1)\n",
      "\tWeight: contours-reduced/bias:0, Shape: (1,)\n",
      "Layer: conv2d_146\n",
      "\tWeight: conv2d_146/kernel:0, Shape: (7, 7, 1, 32)\n",
      "\tWeight: conv2d_146/bias:0, Shape: (32,)\n",
      "Layer: conv2d_148\n",
      "\tWeight: conv2d_148/kernel:0, Shape: (5, 5, 8, 32)\n",
      "\tWeight: conv2d_148/bias:0, Shape: (32,)\n",
      "Layer: batch_normalization_99\n",
      "\tWeight: batch_normalization_99/gamma:0, Shape: (32,)\n",
      "\tWeight: batch_normalization_99/beta:0, Shape: (32,)\n",
      "Layer: conv2d_147\n",
      "\tWeight: conv2d_147/kernel:0, Shape: (7, 3, 32, 1)\n",
      "\tWeight: conv2d_147/bias:0, Shape: (1,)\n",
      "Layer: conv2d_149\n",
      "\tWeight: conv2d_149/kernel:0, Shape: (3, 3, 33, 1)\n",
      "\tWeight: conv2d_149/bias:0, Shape: (1,)\n"
     ]
    }
   ],
   "source": [
    "# PRINT OUT ALL TRAINABLE LAYERS OF THE MODEL\n",
    "# Iterate through the layers and print the layer name and its trainable status\n",
    "for layer in models.model().layers:\n",
    "    print(f\"Layer: {layer.name}\")\n",
    "    print(f\"Trainable: {layer.trainable}\")\n",
    "    for weight in layer.trainable_weights:\n",
    "        print(f\"\\tWeight: {weight.name}, Shape: {weight.shape}\")\n",
    "\n",
    "# If you only want to see layers with trainable weights:\n",
    "print(\"\\nOnly layers with trainable weights:\")\n",
    "for layer in models.model().layers:\n",
    "    if layer.trainable_weights:\n",
    "        print(f\"Layer: {layer.name}\")\n",
    "        for weight in layer.trainable_weights:\n",
    "            print(f\"\\tWeight: {weight.name}, Shape: {weight.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0ab325f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE CUSTOM LOSS FUNCTION FOR WEIGHTED BINARY CROSS ENTROPY\n",
    "class WeightedBinaryCrossEntropy(tf.keras.losses.Loss):\n",
    "    def __init__(self, pos_weight, neg_weight, from_logits=False, name='weighted_binary_crossentropy'):\n",
    "        super().__init__(name=name)\n",
    "        self.pos_weight = pos_weight\n",
    "        self.neg_weight = neg_weight\n",
    "        self.from_logits = from_logits\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        if not self.from_logits:\n",
    "            print(\"y_pred: \", y_pred)\n",
    "            unwrapped_y_pred = self.unwrap_output_custom(y_pred, audio_original_length, n_overlapping_frames)\n",
    "\n",
    "            # Manually calculate the weighted binary cross-entropy for predictions that aren't logits\n",
    "            epsilon = tf.keras.backend.epsilon()\n",
    "            unwrapped_y_pred = tf.clip_by_value(unwrapped_y_pred, epsilon, 1.0 - epsilon)\n",
    "\n",
    "            y_true = tf.cast(y_true, tf.float32)\n",
    "            unwrapped_y_pred = tf.cast(unwrapped_y_pred, tf.float32)\n",
    "            pos_weight = tf.cast(self.pos_weight, tf.float32)\n",
    "            neg_weight = tf.cast(self.neg_weight, tf.float32)\n",
    "\n",
    "            loss = -y_true * tf.math.log(unwrapped_y_pred) * pos_weight - (1.0 - y_true) * tf.math.log(1.0 - unwrapped_y_pred) * neg_weight\n",
    "        else:\n",
    "            # Use TensorFlow's built-in function for logits\n",
    "            loss = tf.nn.weighted_cross_entropy_with_logits(labels=y_true, logits=y_pred, pos_weight=self.pos_weight)\n",
    "\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "    # custom unwrap output function that remains compatible with TensorFlow's graph execution\n",
    "    def unwrap_output_custom(self, output: tf.Tensor, audio_original_length: int, n_overlapping_frames: int) -> tf.Tensor:\n",
    "        \"\"\"Unwrap batched model predictions to a single matrix.\n",
    "\n",
    "        Args:\n",
    "            output: tensor (n_batches, n_times_short, n_freqs)\n",
    "            audio_original_length: length of original audio signal (in samples)\n",
    "            n_overlapping_frames: number of overlapping frames in the output\n",
    "\n",
    "        Returns:\n",
    "            tensor (n_times, n_freqs)\n",
    "        \"\"\"\n",
    "        print(\"output: \", output)\n",
    "        output_rank = tf.rank(output)\n",
    "        print(\"output_rank: \", output_rank)\n",
    "        \n",
    "        def process_output():\n",
    "            n_olap = int(0.5 * n_overlapping_frames)\n",
    "            if n_olap > 0:\n",
    "                output_processed = output[:, n_olap:-n_olap, :]\n",
    "            else:\n",
    "                output_processed = output\n",
    "                \n",
    "            output_shape = tf.shape(output_processed)\n",
    "            n_output_frames_original = tf.cast(tf.floor(audio_original_length * (ANNOTATIONS_FPS / AUDIO_SAMPLE_RATE)), tf.int32)\n",
    "            unwrapped_output = tf.reshape(output_processed, [output_shape[0] * output_shape[1], output_shape[2]])\n",
    "            return unwrapped_output[:n_output_frames_original, :]  # trim to original audio length\n",
    "        \n",
    "        def handle_invalid_rank():\n",
    "            # Print a warning message and return a dummy tensor\n",
    "            tf.print(f\"Warning: Expected output rank to be 3, got {output_rank}\")\n",
    "            return tf.zeros((0, 0), dtype=output.dtype)\n",
    "\n",
    "        return tf.cond(tf.equal(output_rank, 3), process_output, handle_invalid_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b16302a",
   "metadata": {},
   "source": [
    "## Try built-in tensorflow train method\n",
    "\n",
    "This seems to work, the note and onset loss continuously get reduced throughout each epoch! The model is successfully being trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ee256e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "\n",
    "model_train = models.model()\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_function = WeightedBinaryCrossEntropy(pos_weight=0.95, neg_weight=0.05)\n",
    "onset_loss_function = WeightedBinaryCrossEntropy(pos_weight=0.95, neg_weight=0.05)\n",
    "contour_loss_function = WeightedBinaryCrossEntropy(pos_weight=0.95, neg_weight=0.05)\n",
    "note_loss_function = WeightedBinaryCrossEntropy(pos_weight=0.95, neg_weight=0.05)\n",
    "model_train.compile(optimizer=adam_optimizer, loss={\"onset\": onset_loss_function, \"note\": note_loss_function})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b1c8f555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5805/5805 [==============================] - ETA: 0s - loss: 0.0046 - note_loss: 0.0023 - onset_loss: 0.0022y_pred:  Tensor(\"model_27/note/reshape_3/Reshape:0\", shape=(4, 172, 88), dtype=float32)\n",
      "output:  Tensor(\"model_27/note/reshape_3/Reshape:0\", shape=(4, 172, 88), dtype=float32)\n",
      "output_rank:  Tensor(\"weighted_binary_crossentropy/Rank:0\", shape=(), dtype=int32)\n",
      "y_pred:  Tensor(\"model_27/onset/reshape_2/Reshape:0\", shape=(4, 172, 88), dtype=float32)\n",
      "output:  Tensor(\"model_27/onset/reshape_2/Reshape:0\", shape=(4, 172, 88), dtype=float32)\n",
      "output_rank:  Tensor(\"weighted_binary_crossentropy_1/Rank:0\", shape=(), dtype=int32)\n",
      "5805/5805 [==============================] - 2631s 453ms/step - loss: 0.0046 - note_loss: 0.0023 - onset_loss: 0.0022 - val_loss: 0.0039 - val_note_loss: 0.0018 - val_onset_loss: 0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e07aab9670>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "num_epochs = 1\n",
    "model_train.fit(train_dataset, batch_size=16, epochs=num_epochs, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9d3496f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/nov06\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/nov06\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save our trained version of the model\n",
    "\n",
    "model_train.save('saved_models/nov06')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5dfc96",
   "metadata": {},
   "source": [
    "## Try Custom Training Loop Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "483f0658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIALIZED NEW MODEL (training from scratch)\n",
      "\n",
      "Epoch 1/5:\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "Step 0: loss = 0.0616, accuracy = TBD\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "None gradient for batch_normalization_52/gamma:0\n",
      "None gradient for batch_normalization_52/beta:0\n",
      "None gradient for conv2d_79/kernel:0\n",
      "None gradient for conv2d_79/bias:0\n",
      "None gradient for batch_normalization_54/gamma:0\n",
      "None gradient for batch_normalization_54/beta:0\n",
      "None gradient for contours-reduced/kernel:0\n",
      "None gradient for contours-reduced/bias:0\n",
      "None gradient for conv2d_80/kernel:0\n",
      "None gradient for conv2d_80/bias:0\n",
      "None gradient for conv2d_82/kernel:0\n",
      "None gradient for conv2d_82/bias:0\n",
      "None gradient for batch_normalization_55/gamma:0\n",
      "None gradient for batch_normalization_55/beta:0\n",
      "None gradient for conv2d_81/kernel:0\n",
      "None gradient for conv2d_81/bias:0\n",
      "None gradient for conv2d_83/kernel:0\n",
      "None gradient for conv2d_83/bias:0\n",
      "Gradients:  [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "Gradients and vars:  []\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "Step 10: loss = 0.0617, accuracy = TBD\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "logits['onset'].shape:  (4, 172, 88)\n",
      "unwrapped_output['onset'].shape:  (430, 88)\n",
      "Step 20: loss = 0.0617, accuracy = TBD\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\_AlexFiles\\Coding\\Python\\FALL2023_IndependentStudy\\audio_to_midi_vst\\independent_study\\Training.ipynb Cell 31\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#X33sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, (x, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataset):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#X33sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#X33sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#X33sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#X33sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         logits \u001b[39m=\u001b[39m model(x, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#X33sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlogits[\u001b[39m\u001b[39m'\u001b[39m\u001b[39monset\u001b[39m\u001b[39m'\u001b[39m\u001b[39m].shape: \u001b[39m\u001b[39m\"\u001b[39m, logits[\u001b[39m'\u001b[39m\u001b[39monset\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/_AlexFiles/Coding/Python/FALL2023_IndependentStudy/audio_to_midi_vst/independent_study/Training.ipynb#X33sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         \u001b[39m# Process output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\keras\\src\\engine\\training.py:569\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    567\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 569\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1149\u001b[0m ):\n\u001b[1;32m-> 1150\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\keras\\src\\engine\\functional.py:512\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    494\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    495\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \n\u001b[0;32m    497\u001b[0m \u001b[39m    In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[39m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 512\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\keras\\src\\engine\\functional.py:669\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    666\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    668\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 669\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39;49mlayer(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    671\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    672\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[0;32m    673\u001b[0m     node\u001b[39m.\u001b[39mflat_output_ids, tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(outputs)\n\u001b[0;32m    674\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:1150\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1149\u001b[0m ):\n\u001b[1;32m-> 1150\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\basic_pitch\\layers\\signal.py:180\u001b[0m, in \u001b[0;36mNormalizedLog.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    177\u001b[0m log_power_min \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mreduce_min(log_power, axis\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m]), [tf\u001b[39m.\u001b[39mshape(inputs)[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m])\n\u001b[0;32m    178\u001b[0m log_power_offset \u001b[39m=\u001b[39m log_power \u001b[39m-\u001b[39m log_power_min\n\u001b[0;32m    179\u001b[0m log_power_offset_max \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(\n\u001b[1;32m--> 180\u001b[0m     tf\u001b[39m.\u001b[39;49mmath\u001b[39m.\u001b[39;49mreduce_max(log_power_offset, axis\u001b[39m=\u001b[39;49m[\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m]),\n\u001b[0;32m    181\u001b[0m     [tf\u001b[39m.\u001b[39mshape(inputs)[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m],\n\u001b[0;32m    182\u001b[0m )\n\u001b[0;32m    183\u001b[0m log_power_normalized \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mdivide_no_nan(log_power_offset, log_power_offset_max)\n\u001b[0;32m    185\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mreshape(log_power_normalized, tf\u001b[39m.\u001b[39mshape(inputs))\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3185\u001b[0m, in \u001b[0;36mreduce_max\u001b[1;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[0;32m   3139\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmath.reduce_max\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreduce_max\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m   3140\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m   3141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce_max\u001b[39m(input_tensor, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   3142\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Computes `tf.math.maximum` of elements across dimensions of a tensor.\u001b[39;00m\n\u001b[0;32m   3143\u001b[0m \n\u001b[0;32m   3144\u001b[0m \u001b[39m  This is the reduction operation for the elementwise `tf.math.maximum` op.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3183\u001b[0m \u001b[39m    The reduced tensor.\u001b[39;00m\n\u001b[0;32m   3184\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3185\u001b[0m   \u001b[39mreturn\u001b[39;00m reduce_max_with_dims(input_tensor, axis, keepdims, name,\n\u001b[0;32m   3186\u001b[0m                               _ReductionDims(input_tensor, axis))\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3197\u001b[0m, in \u001b[0;36mreduce_max_with_dims\u001b[1;34m(input_tensor, axis, keepdims, name, dims)\u001b[0m\n\u001b[0;32m   3189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce_max_with_dims\u001b[39m(input_tensor,\n\u001b[0;32m   3190\u001b[0m                          axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   3191\u001b[0m                          keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   3192\u001b[0m                          name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   3193\u001b[0m                          dims\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   3194\u001b[0m   keepdims \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m keepdims \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mbool\u001b[39m(keepdims)\n\u001b[0;32m   3195\u001b[0m   \u001b[39mreturn\u001b[39;00m _may_reduce_to_scalar(\n\u001b[0;32m   3196\u001b[0m       keepdims, axis,\n\u001b[1;32m-> 3197\u001b[0m       gen_math_ops\u001b[39m.\u001b[39;49m_max(input_tensor, dims, keepdims, name\u001b[39m=\u001b[39;49mname))\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6809\u001b[0m, in \u001b[0;36m_max\u001b[1;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[0;32m   6807\u001b[0m   \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   6808\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 6809\u001b[0m   \u001b[39mreturn\u001b[39;00m _max_eager_fallback(\n\u001b[0;32m   6810\u001b[0m       \u001b[39minput\u001b[39;49m, axis, keep_dims\u001b[39m=\u001b[39;49mkeep_dims, name\u001b[39m=\u001b[39;49mname, ctx\u001b[39m=\u001b[39;49m_ctx)\n\u001b[0;32m   6811\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_SymbolicException:\n\u001b[0;32m   6812\u001b[0m   \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6841\u001b[0m, in \u001b[0;36m_max_eager_fallback\u001b[1;34m(input, axis, keep_dims, name, ctx)\u001b[0m\n\u001b[0;32m   6839\u001b[0m _inputs_flat \u001b[39m=\u001b[39m [\u001b[39minput\u001b[39m, axis]\n\u001b[0;32m   6840\u001b[0m _attrs \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mkeep_dims\u001b[39m\u001b[39m\"\u001b[39m, keep_dims, \u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, _attr_T, \u001b[39m\"\u001b[39m\u001b[39mTidx\u001b[39m\u001b[39m\"\u001b[39m, _attr_Tidx)\n\u001b[1;32m-> 6841\u001b[0m _result \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39;49mexecute(\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mMax\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m1\u001b[39;49m, inputs\u001b[39m=\u001b[39;49m_inputs_flat, attrs\u001b[39m=\u001b[39;49m_attrs,\n\u001b[0;32m   6842\u001b[0m                            ctx\u001b[39m=\u001b[39;49mctx, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   6843\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n\u001b[0;32m   6844\u001b[0m   _execute\u001b[39m.\u001b[39mrecord_gradient(\n\u001b[0;32m   6845\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mMax\u001b[39m\u001b[39m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\anaconda3\\envs\\MusicTranscriber\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "epoch_train_loss = []\n",
    "epoch_val_loss = []\n",
    "n_overlapping_frames = 30\n",
    "audio_original_length = 110250\n",
    "\n",
    "# initialize spotify basic pitch model\n",
    "model = models.model()\n",
    "\n",
    "# Initialize the model\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_function = WeightedBinaryCrossEntropy(pos_weight=0.95, neg_weight=0.05)\n",
    "model.compile(optimizer=adam_optimizer, loss=loss_function)\n",
    "print(\"INITIALIZED NEW MODEL (training from scratch)\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}:\")\n",
    "    \n",
    "    train_loss = []\n",
    "    # Training\n",
    "    # Loop through training set batches (batch size 1 for now)\n",
    "    for idx, (x, y) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "        \n",
    "            # Forward pass\n",
    "            logits = model(x, training=True)\n",
    "\n",
    "            print(\"logits['onset'].shape: \", logits['onset'].shape)\n",
    "            # Process output\n",
    "            unwrapped_output = {k: inference.unwrap_output(logits[k], audio_original_length, n_overlapping_frames) for k in logits}\n",
    "            \n",
    "            print(\"unwrapped_output['onset'].shape: \", unwrapped_output['onset'].shape)\n",
    "            # Compute loss for onsets\n",
    "            loss_value_onsets = loss_function(y, unwrapped_output['onset'])\n",
    "\n",
    "            # Compute loss for notes\n",
    "            loss_value_notes = loss_function(y, unwrapped_output['note'])\n",
    "\n",
    "            # average loss\n",
    "            loss_value = (loss_value_onsets + loss_value_notes) / 2\n",
    "\n",
    "            gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "            grads_and_vars = [(grad, var) for grad, var in zip(gradients, model.trainable_weights) if grad is not None]\n",
    "\n",
    "            if idx == 1 and epoch == 0:\n",
    "                for grad, var in zip(gradients, model.trainable_weights):\n",
    "                    if grad is None:\n",
    "                        print(f\"None gradient for {var.name}\")\n",
    "                print(\"Gradients: \", gradients)\n",
    "                print(\"Gradients and vars: \", grads_and_vars)\n",
    "                \n",
    "            # Update weights\n",
    "            adam_optimizer.apply_gradients(grads_and_vars)\n",
    "            \n",
    "            # record loss\n",
    "            train_loss.append(loss_value)\n",
    "        \n",
    "\n",
    "            # Print progress\n",
    "            if idx % 10 == 0:\n",
    "                print(f\"Step {idx}: loss = {loss_value:.4f}, accuracy = TBD\")\n",
    "            \n",
    "    # Reset metric at the end of epoch\n",
    "    avgLoss = np.mean(train_loss)\n",
    "    epoch_train_loss.append(avgLoss)\n",
    "    print(\"Epoch {}/{} training loss: {}\".format(epoch+1, num_epochs, avgLoss))\n",
    "\n",
    "    # Validation\n",
    "    val_loss = []\n",
    "     # Loop through validation set batches (batch size 1 for now)\n",
    "    for idx, (x, y) in enumerate(val_dataset):\n",
    "        # Forward pass\n",
    "        logits = model(x, training=False)\n",
    "\n",
    "        # Process output\n",
    "        unwrapped_output = {k: inference.unwrap_output(logits[k], audio_original_length, n_overlapping_frames) for k in logits}\n",
    "\n",
    "        # Compute loss for onsets\n",
    "        loss_value_onsets = loss_function(y, unwrapped_output['onset'])\n",
    "\n",
    "        # Compute loss for notes\n",
    "        loss_value_notes = loss_function(y, unwrapped_output['note'])\n",
    "\n",
    "        # average loss\n",
    "        loss_value = (loss_value_onsets + loss_value_notes) / 2\n",
    "    \n",
    "        # record loss\n",
    "        val_loss.append(loss_value)\n",
    "        \n",
    "    avgLoss = np.mean(val_loss)\n",
    "    epoch_val_loss.append(avgLoss)\n",
    "    print(\"Epoch {}/{} validation loss: {}\".format(epoch+1, num_epochs, avgLoss))\n",
    "\n",
    "plt.plot(epoch_train_loss)\n",
    "plt.plot(epoch_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae32d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/oct10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/oct10\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_models/oct10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac43be2",
   "metadata": {},
   "source": [
    "## Test Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ec007024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Basic Pitch  \n",
      "\n",
      "\n",
      "Importing Tensorflow (this may take a few seconds)...\n",
      "\n",
      "Predicting MIDI for model_predictions\\_test_audio\\beethoven_fur_elise.mp3...\n",
      "\n",
      "\n",
      "  Creating midi...\n",
      "   Saved to model_predictions\\our_model\\beethoven_fur_elise_basic_pitch.mid\n",
      "\n",
      " Done \n",
      "\n",
      "\n",
      "\n",
      " Basic Pitch  \n",
      "\n",
      "\n",
      "Importing Tensorflow (this may take a few seconds)...\n",
      "\n",
      "Predicting MIDI for model_predictions\\_test_audio\\beethoven_fur_elise.mp3...\n",
      "\n",
      "\n",
      "  Creating midi...\n",
      "   model_predictions\\spotify_model\\beethoven_fur_elise_basic_pitch.mid already exists and would be overwritten. Skipping output files for model_predictions\\_test_audio\\beethoven_fur_elise.mp3.\n",
      "\n",
      "\n",
      " Basic Pitch  \n",
      "\n",
      "\n",
      "Importing Tensorflow (this may take a few seconds)...\n",
      "\n",
      "Predicting MIDI for model_predictions\\_test_audio\\wii_music.mp3...\n",
      "\n",
      "\n",
      "  Creating midi...\n",
      "   Saved to model_predictions\\our_model\\wii_music_basic_pitch.mid\n",
      "\n",
      " Done \n",
      "\n",
      "\n",
      "\n",
      " Basic Pitch  \n",
      "\n",
      "\n",
      "Importing Tensorflow (this may take a few seconds)...\n",
      "\n",
      "Predicting MIDI for model_predictions\\_test_audio\\wii_music.mp3...\n",
      "\n",
      "\n",
      "  Creating midi...\n",
      "   model_predictions\\spotify_model\\wii_music_basic_pitch.mid already exists and would be overwritten. Skipping output files for model_predictions\\_test_audio\\wii_music.mp3.\n"
     ]
    }
   ],
   "source": [
    "# command line execution to output resulting midi from trained model\n",
    "!python ../basic_pitch_original/basic_pitch/predict.py --model_path \"saved_models/nov06\" \"model_predictions/our_model/\" \"model_predictions/_test_audio/beethoven_fur_elise.mp3\"\n",
    "!python ../basic_pitch_original/basic_pitch/predict.py \"model_predictions/spotify_model/\" \"model_predictions/_test_audio/beethoven_fur_elise.mp3\"\n",
    "!python ../basic_pitch_original/basic_pitch/predict.py --model_path \"saved_models/nov06\" \"model_predictions/our_model/\" \"model_predictions/_test_audio/wii_music.mp3\"\n",
    "!python ../basic_pitch_original/basic_pitch/predict.py \"model_predictions/spotify_model/\" \"model_predictions/_test_audio/wii_music.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e3c169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "61ce0196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\_AlexFiles\\Coding\\Python\\FALL2023_IndependentStudy\\audio_to_midi_vst\n",
      "OG Model path:  c:\\_AlexFiles\\Coding\\Python\\FALL2023_IndependentStudy\\audio_to_midi_vst/basic_pitch_original/basic_pitch/saved_models/icassp_2022/nmp\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from tensorflow import Tensor, signal, keras, saved_model\n",
    "\n",
    "current_directory = Path.cwd()\n",
    "print(current_directory.parent)\n",
    "icassp_2022_model_path = str(current_directory.parent) + \"/basic_pitch_original/basic_pitch/saved_models/icassp_2022/nmp\"\n",
    "print(\"OG Model path: \", icassp_2022_model_path)\n",
    "model_oct10 = saved_model.load('saved_models/oct10')\n",
    "model_nov06 = saved_model.load('saved_models/nov06')\n",
    "model_bp = saved_model.load(icassp_2022_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "21938e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\_AlexFiles\\Coding\\Python\\FALL2023_IndependentStudy\\audio_to_midi_vst\\independent_study\\model_predictions\\_test_audio\\beethoven_fur_elise.mp3\n"
     ]
    }
   ],
   "source": [
    "# create sample for 1 song (Fur Elise by Beethoven)\n",
    "beethoven_x = []\n",
    "\n",
    "offset = 10 #seconds\n",
    "\n",
    "beethoven_file = current_directory / \"model_predictions/_test_audio/beethoven_fur_elise.mp3\"\n",
    "print(beethoven_file)\n",
    "while offset < librosa.get_duration(path=beethoven_file) - SPLIT_INTERVAL:\n",
    "    # preprocess audio\n",
    "\n",
    "    n_overlapping_frames = 30\n",
    "    overlap_len = n_overlapping_frames * FFT_HOP\n",
    "    hop_size = AUDIO_N_SAMPLES - overlap_len\n",
    "\n",
    "    # modified get_input_audio function to get audio from offset\n",
    "    assert overlap_len % 2 == 0, \"overlap_length must be even, got {}\".format(overlap_len)\n",
    "    audio_original, _ = librosa.load(beethoven_file, sr=AUDIO_SAMPLE_RATE, offset=offset, duration=SPLIT_INTERVAL, mono=True)\n",
    "\n",
    "    original_length = audio_original.shape[0]\n",
    "    audio_original = np.concatenate([np.zeros((int(overlap_len / 2),), dtype=np.float32), audio_original])\n",
    "    audio_windowed, window_times = inference.window_audio_file(audio_original, hop_size)\n",
    "\n",
    "    beethoven_x.append(audio_windowed)\n",
    "    offset += SPLIT_INTERVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3a40e14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'onset': <tf.Tensor: shape=(4, 172, 88), dtype=float32, numpy=\n",
       " array([[[0.2563653 , 0.14136553, 0.11154418, ..., 0.10882651,\n",
       "          0.136962  , 0.16868067],\n",
       "         [0.18752408, 0.1122677 , 0.09407169, ..., 0.07430211,\n",
       "          0.08307945, 0.10704739],\n",
       "         [0.17874199, 0.12020129, 0.11011477, ..., 0.08455317,\n",
       "          0.0864543 , 0.10679121],\n",
       "         ...,\n",
       "         [0.09266827, 0.11102663, 0.10919577, ..., 0.09788323,\n",
       "          0.10385687, 0.08499473],\n",
       "         [0.0693486 , 0.07680301, 0.09822215, ..., 0.08400798,\n",
       "          0.11336812, 0.08087544],\n",
       "         [0.08666889, 0.08257812, 0.10162653, ..., 0.08861089,\n",
       "          0.11391509, 0.10966828]],\n",
       " \n",
       "        [[0.21780737, 0.16268659, 0.12284816, ..., 0.11596433,\n",
       "          0.13623056, 0.14814657],\n",
       "         [0.22107677, 0.14205264, 0.11213985, ..., 0.10483827,\n",
       "          0.1084298 , 0.11917666],\n",
       "         [0.17761321, 0.11661748, 0.13201249, ..., 0.10609926,\n",
       "          0.09241855, 0.12110808],\n",
       "         ...,\n",
       "         [0.08610087, 0.12242878, 0.11606333, ..., 0.09609546,\n",
       "          0.09428981, 0.093869  ],\n",
       "         [0.06835827, 0.09895062, 0.09735635, ..., 0.07886452,\n",
       "          0.08113547, 0.07508726],\n",
       "         [0.08820201, 0.10476375, 0.1056366 , ..., 0.10531621,\n",
       "          0.10232968, 0.11323157]],\n",
       " \n",
       "        [[0.20771246, 0.22627191, 0.07632162, ..., 0.15181132,\n",
       "          0.13440762, 0.16006486],\n",
       "         [0.19397657, 0.17729785, 0.06541061, ..., 0.10709889,\n",
       "          0.09801103, 0.11912216],\n",
       "         [0.13800733, 0.13289516, 0.08494262, ..., 0.11138808,\n",
       "          0.09553221, 0.12246042],\n",
       "         ...,\n",
       "         [0.0856707 , 0.10144525, 0.08257282, ..., 0.11509896,\n",
       "          0.11115806, 0.11395627],\n",
       "         [0.08406276, 0.09526161, 0.08024851, ..., 0.09516796,\n",
       "          0.09604733, 0.08832332],\n",
       "         [0.13610415, 0.12961312, 0.13329397, ..., 0.14713766,\n",
       "          0.14548458, 0.14360568]],\n",
       " \n",
       "        [[0.1667379 , 0.25194666, 0.14034265, ..., 0.10568167,\n",
       "          0.1217957 , 0.1449523 ],\n",
       "         [0.14089037, 0.19623691, 0.12796776, ..., 0.09299331,\n",
       "          0.10295247, 0.10708019],\n",
       "         [0.11971799, 0.17263335, 0.15099815, ..., 0.09654404,\n",
       "          0.10298325, 0.1147939 ],\n",
       "         ...,\n",
       "         [0.02635491, 0.09602998, 0.1176933 , ..., 0.11520823,\n",
       "          0.1112219 , 0.11390202],\n",
       "         [0.02148855, 0.07363718, 0.0948517 , ..., 0.09520996,\n",
       "          0.09606979, 0.08830359],\n",
       "         [0.05069439, 0.05230723, 0.09190635, ..., 0.14715561,\n",
       "          0.14549173, 0.1435963 ]]], dtype=float32)>,\n",
       " 'contour': <tf.Tensor: shape=(4, 172, 264), dtype=float32, numpy=\n",
       " array([[[0.1890218 , 0.1350127 , 0.13556974, ..., 0.14065363,\n",
       "          0.12220054, 0.15154873],\n",
       "         [0.16469471, 0.1123905 , 0.11831106, ..., 0.10621057,\n",
       "          0.09045599, 0.11729096],\n",
       "         [0.14128764, 0.09716584, 0.11042503, ..., 0.1040068 ,\n",
       "          0.08070467, 0.1008008 ],\n",
       "         ...,\n",
       "         [0.10824199, 0.09326684, 0.08981899, ..., 0.09721242,\n",
       "          0.08809844, 0.09968442],\n",
       "         [0.12441322, 0.10479581, 0.0999561 , ..., 0.10636419,\n",
       "          0.11597922, 0.12413245],\n",
       "         [0.14330068, 0.12016942, 0.1097055 , ..., 0.12406832,\n",
       "          0.13778985, 0.15612245]],\n",
       " \n",
       "        [[0.14667505, 0.12047653, 0.11065898, ..., 0.11971349,\n",
       "          0.11706977, 0.14469485],\n",
       "         [0.1227444 , 0.09376314, 0.10233591, ..., 0.10877207,\n",
       "          0.10419   , 0.1256375 ],\n",
       "         [0.10791583, 0.08491886, 0.09913399, ..., 0.09733561,\n",
       "          0.08825471, 0.10211526],\n",
       "         ...,\n",
       "         [0.09146445, 0.08416556, 0.09869305, ..., 0.10039308,\n",
       "          0.09222895, 0.11358477],\n",
       "         [0.10748257, 0.09502156, 0.10766523, ..., 0.10794708,\n",
       "          0.11759435, 0.13527487],\n",
       "         [0.13298205, 0.11863788, 0.12074433, ..., 0.12863612,\n",
       "          0.14201091, 0.16738763]],\n",
       " \n",
       "        [[0.14056884, 0.11778109, 0.10774891, ..., 0.12873599,\n",
       "          0.12218186, 0.15143993],\n",
       "         [0.11307887, 0.09083515, 0.09805622, ..., 0.1044277 ,\n",
       "          0.09775355, 0.12018266],\n",
       "         [0.0998326 , 0.08441302, 0.10001693, ..., 0.10220808,\n",
       "          0.08652854, 0.10082591],\n",
       "         ...,\n",
       "         [0.10709686, 0.09352652, 0.09855264, ..., 0.10601553,\n",
       "          0.08395995, 0.1028235 ],\n",
       "         [0.12511463, 0.1078608 , 0.10810728, ..., 0.11142772,\n",
       "          0.10951295, 0.12583852],\n",
       "         [0.15812743, 0.1409627 , 0.13660295, ..., 0.14650936,\n",
       "          0.14671712, 0.17054354]],\n",
       " \n",
       "        [[0.14214684, 0.12451527, 0.11981604, ..., 0.12264753,\n",
       "          0.11647382, 0.14286475],\n",
       "         [0.11929358, 0.09888361, 0.10702185, ..., 0.10361733,\n",
       "          0.09654645, 0.11865448],\n",
       "         [0.09918464, 0.0886443 , 0.10124494, ..., 0.10011131,\n",
       "          0.08470578, 0.10190488],\n",
       "         ...,\n",
       "         [0.18477137, 0.09135439, 0.10385185, ..., 0.10601553,\n",
       "          0.08395995, 0.1028235 ],\n",
       "         [0.19587106, 0.10947493, 0.11515701, ..., 0.11142772,\n",
       "          0.10951295, 0.12583852],\n",
       "         [0.21474922, 0.14350447, 0.13829882, ..., 0.14650936,\n",
       "          0.14671712, 0.17054354]]], dtype=float32)>,\n",
       " 'note': <tf.Tensor: shape=(4, 172, 88), dtype=float32, numpy=\n",
       " array([[[0.15636654, 0.12511563, 0.1277601 , ..., 0.1290295 ,\n",
       "          0.13226452, 0.15008876],\n",
       "         [0.13491684, 0.10577384, 0.10870846, ..., 0.11052965,\n",
       "          0.11258917, 0.12666756],\n",
       "         [0.12478486, 0.1005984 , 0.10410176, ..., 0.10565041,\n",
       "          0.10722558, 0.11528426],\n",
       "         ...,\n",
       "         [0.12674496, 0.10716815, 0.10608733, ..., 0.1083345 ,\n",
       "          0.1095429 , 0.12155848],\n",
       "         [0.13810444, 0.11336484, 0.11214932, ..., 0.11343838,\n",
       "          0.11439439, 0.13299017],\n",
       "         [0.16041434, 0.13317528, 0.13187474, ..., 0.13213192,\n",
       "          0.13306434, 0.15537858]],\n",
       " \n",
       "        [[0.15205693, 0.12961647, 0.12791316, ..., 0.12673004,\n",
       "          0.1308365 , 0.15382378],\n",
       "         [0.12969528, 0.10966168, 0.10796184, ..., 0.10662862,\n",
       "          0.1098863 , 0.12967336],\n",
       "         [0.11876149, 0.10376547, 0.10208755, ..., 0.10074514,\n",
       "          0.10365493, 0.11810256],\n",
       "         ...,\n",
       "         [0.12364449, 0.10729369, 0.10626073, ..., 0.10791286,\n",
       "          0.10832047, 0.12368686],\n",
       "         [0.13562706, 0.11342788, 0.1121192 , ..., 0.11319165,\n",
       "          0.11355544, 0.13488892],\n",
       "         [0.15857087, 0.13323706, 0.13189957, ..., 0.13172105,\n",
       "          0.13220912, 0.15680161]],\n",
       " \n",
       "        [[0.1517236 , 0.1259004 , 0.1274389 , ..., 0.12766774,\n",
       "          0.1310857 , 0.15294431],\n",
       "         [0.12925676, 0.10567941, 0.10768877, ..., 0.10828803,\n",
       "          0.11062301, 0.12938319],\n",
       "         [0.11819945, 0.09930013, 0.10200619, ..., 0.10268679,\n",
       "          0.10453673, 0.11813847],\n",
       "         ...,\n",
       "         [0.12761022, 0.1106603 , 0.10775825, ..., 0.11111864,\n",
       "          0.11268451, 0.12199416],\n",
       "         [0.13867325, 0.11577553, 0.11278988, ..., 0.11605171,\n",
       "          0.11724877, 0.13299733],\n",
       "         [0.16016488, 0.1339299 , 0.13091382, ..., 0.13307218,\n",
       "          0.13441566, 0.15421583]],\n",
       " \n",
       "        [[0.15290064, 0.12788516, 0.12621342, ..., 0.12810367,\n",
       "          0.12957543, 0.15261064],\n",
       "         [0.13063768, 0.10786356, 0.10659072, ..., 0.10823688,\n",
       "          0.10879247, 0.1287227 ],\n",
       "         [0.11977954, 0.10189816, 0.10122395, ..., 0.10237488,\n",
       "          0.10248683, 0.11723159],\n",
       "         ...,\n",
       "         [0.12928936, 0.10778888, 0.10851701, ..., 0.11219013,\n",
       "          0.11332648, 0.12137115],\n",
       "         [0.13988088, 0.1131453 , 0.11355001, ..., 0.11647866,\n",
       "          0.11742202, 0.13267927],\n",
       "         [0.16070741, 0.13115373, 0.13146833, ..., 0.13315366,\n",
       "          0.13443634, 0.1541998 ]]], dtype=float32)>}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bp(beethoven_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2891b644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'onset': <tf.Tensor: shape=(4, 172, 88), dtype=float32, numpy=\n",
       " array([[[0.444482  , 0.31237635, 0.20683138, ..., 0.61643285,\n",
       "          0.7267155 , 0.5396218 ],\n",
       "         [0.30873603, 0.12919618, 0.10692903, ..., 0.4448164 ,\n",
       "          0.51427305, 0.48544478],\n",
       "         [0.5374681 , 0.18853362, 0.13876264, ..., 0.458224  ,\n",
       "          0.5304953 , 0.4897275 ],\n",
       "         ...,\n",
       "         [0.36935937, 0.5306894 , 0.5449164 , ..., 0.320996  ,\n",
       "          0.23089427, 0.26329532],\n",
       "         [0.36367205, 0.60169804, 0.6845523 , ..., 0.32479608,\n",
       "          0.3278274 , 0.2771007 ],\n",
       "         [0.35844558, 0.51667976, 0.43400443, ..., 0.33894673,\n",
       "          0.34691682, 0.33619347]],\n",
       " \n",
       "        [[0.3036792 , 0.31951433, 0.3827361 , ..., 0.58958495,\n",
       "          0.67314124, 0.56244427],\n",
       "         [0.3735905 , 0.6404076 , 0.60093606, ..., 0.54255474,\n",
       "          0.64743936, 0.46937564],\n",
       "         [0.3643065 , 0.5471824 , 0.45531607, ..., 0.525807  ,\n",
       "          0.53859895, 0.45449227],\n",
       "         ...,\n",
       "         [0.38378203, 0.6118602 , 0.6061289 , ..., 0.3538837 ,\n",
       "          0.2921635 , 0.29510733],\n",
       "         [0.34891576, 0.4577563 , 0.53865105, ..., 0.45028132,\n",
       "          0.33025452, 0.38001248],\n",
       "         [0.41525447, 0.46862963, 0.3770013 , ..., 0.3765598 ,\n",
       "          0.29837784, 0.3597158 ]],\n",
       " \n",
       "        [[0.3591288 , 0.2675017 , 0.31473443, ..., 0.6248674 ,\n",
       "          0.68070304, 0.58830094],\n",
       "         [0.5609957 , 0.747586  , 0.636966  , ..., 0.4627132 ,\n",
       "          0.5638818 , 0.560573  ],\n",
       "         [0.44170007, 0.7601428 , 0.585437  , ..., 0.53440565,\n",
       "          0.4813252 , 0.49557668],\n",
       "         ...,\n",
       "         [0.32242402, 0.5236948 , 0.31444815, ..., 0.42508346,\n",
       "          0.48764843, 0.4849502 ],\n",
       "         [0.39593714, 0.5643935 , 0.45560077, ..., 0.332395  ,\n",
       "          0.36327103, 0.4185395 ],\n",
       "         [0.4412133 , 0.5513148 , 0.40255693, ..., 0.19930963,\n",
       "          0.22162934, 0.25841233]],\n",
       " \n",
       "        [[0.42724663, 0.3618461 , 0.31701022, ..., 0.6839777 ,\n",
       "          0.63464385, 0.534367  ],\n",
       "         [0.58237547, 0.70104146, 0.39609897, ..., 0.6953381 ,\n",
       "          0.5919332 , 0.417735  ],\n",
       "         [0.5238826 , 0.6349486 , 0.4375976 , ..., 0.55589384,\n",
       "          0.3522996 , 0.36768213],\n",
       "         ...,\n",
       "         [0.5095489 , 0.08371094, 0.08113132, ..., 0.42507854,\n",
       "          0.48793763, 0.48574796],\n",
       "         [0.59163266, 0.09128703, 0.1083324 , ..., 0.33120632,\n",
       "          0.36191925, 0.41790715],\n",
       "         [0.4673513 , 0.2662839 , 0.25533152, ..., 0.19913772,\n",
       "          0.22129166, 0.25785023]]], dtype=float32)>,\n",
       " 'contour': <tf.Tensor: shape=(4, 172, 264), dtype=float32, numpy=\n",
       " array([[[0.48823962, 0.49376538, 0.51603925, ..., 0.53429836,\n",
       "          0.48027876, 0.47857478],\n",
       "         [0.48174804, 0.4699134 , 0.4838465 , ..., 0.1892951 ,\n",
       "          0.19564435, 0.18465596],\n",
       "         [0.49557206, 0.4734549 , 0.48708925, ..., 0.3307731 ,\n",
       "          0.28166103, 0.3421234 ],\n",
       "         ...,\n",
       "         [0.5134695 , 0.11832342, 0.21173535, ..., 0.3219134 ,\n",
       "          0.57917535, 0.5065367 ],\n",
       "         [0.432595  , 0.20536107, 0.1763415 , ..., 0.4273015 ,\n",
       "          0.5697841 , 0.5385813 ],\n",
       "         [0.46095893, 0.32715005, 0.28045082, ..., 0.4253418 ,\n",
       "          0.4665733 , 0.48949307]],\n",
       " \n",
       "        [[0.50515974, 0.27468005, 0.28626102, ..., 0.32673532,\n",
       "          0.3788669 , 0.42255735],\n",
       "         [0.5427542 , 0.43065995, 0.4569557 , ..., 0.5449548 ,\n",
       "          0.5753377 , 0.56340224],\n",
       "         [0.3818481 , 0.13588312, 0.12100475, ..., 0.08744384,\n",
       "          0.21485233, 0.15918952],\n",
       "         ...,\n",
       "         [0.51984984, 0.18476243, 0.19997607, ..., 0.38919517,\n",
       "          0.48513445, 0.4941798 ],\n",
       "         [0.3150329 , 0.10513512, 0.09011633, ..., 0.42471322,\n",
       "          0.5217925 , 0.5242949 ],\n",
       "         [0.3826801 , 0.3116427 , 0.11063662, ..., 0.38223642,\n",
       "          0.49302298, 0.43741807]],\n",
       " \n",
       "        [[0.55112773, 0.32770023, 0.44816366, ..., 0.27334392,\n",
       "          0.32029614, 0.37721944],\n",
       "         [0.42289233, 0.40793428, 0.617617  , ..., 0.30680013,\n",
       "          0.3471388 , 0.35186854],\n",
       "         [0.34227747, 0.20033471, 0.2132255 , ..., 0.24563201,\n",
       "          0.30759758, 0.45335692],\n",
       "         ...,\n",
       "         [0.42417276, 0.32259953, 0.22271107, ..., 0.23609026,\n",
       "          0.29791918, 0.27628794],\n",
       "         [0.34127715, 0.31020585, 0.31367376, ..., 0.3531398 ,\n",
       "          0.3889668 , 0.35878348],\n",
       "         [0.40016758, 0.35125747, 0.38419208, ..., 0.2877812 ,\n",
       "          0.33579874, 0.35990843]],\n",
       " \n",
       "        [[0.6867224 , 0.48191538, 0.4028426 , ..., 0.4244288 ,\n",
       "          0.4140117 , 0.39032394],\n",
       "         [0.6845535 , 0.5802947 , 0.728588  , ..., 0.5666723 ,\n",
       "          0.6187236 , 0.5598326 ],\n",
       "         [0.54745656, 0.2685596 , 0.27334198, ..., 0.27369502,\n",
       "          0.3539152 , 0.37706828],\n",
       "         ...,\n",
       "         [0.48690152, 0.3433086 , 0.23654427, ..., 0.23609026,\n",
       "          0.29791918, 0.27628794],\n",
       "         [0.2769122 , 0.15590933, 0.16068804, ..., 0.3531398 ,\n",
       "          0.3889668 , 0.35878348],\n",
       "         [0.48926863, 0.36653382, 0.28427726, ..., 0.2877812 ,\n",
       "          0.33579874, 0.35990843]]], dtype=float32)>,\n",
       " 'note': <tf.Tensor: shape=(4, 172, 88), dtype=float32, numpy=\n",
       " array([[[0.5146035 , 0.5740018 , 0.5652945 , ..., 0.5329532 ,\n",
       "          0.52960086, 0.5305283 ],\n",
       "         [0.5437765 , 0.58915365, 0.586108  , ..., 0.55272716,\n",
       "          0.5439963 , 0.51967454],\n",
       "         [0.5813332 , 0.6169889 , 0.59545463, ..., 0.5537677 ,\n",
       "          0.55412793, 0.52646637],\n",
       "         ...,\n",
       "         [0.54538924, 0.55583453, 0.5616449 , ..., 0.5299423 ,\n",
       "          0.5423446 , 0.50626963],\n",
       "         [0.54364187, 0.56041163, 0.5582209 , ..., 0.544572  ,\n",
       "          0.5541811 , 0.51991916],\n",
       "         [0.5288244 , 0.54868186, 0.5359977 , ..., 0.5254918 ,\n",
       "          0.53558934, 0.5347358 ]],\n",
       " \n",
       "        [[0.5204513 , 0.54652715, 0.5406635 , ..., 0.5167193 ,\n",
       "          0.5311339 , 0.5281942 ],\n",
       "         [0.5455002 , 0.57221967, 0.56859237, ..., 0.5326125 ,\n",
       "          0.53641194, 0.51425296],\n",
       "         [0.5707601 , 0.6080178 , 0.59574896, ..., 0.53256786,\n",
       "          0.56117743, 0.5321285 ],\n",
       "         ...,\n",
       "         [0.5434913 , 0.5516712 , 0.5514766 , ..., 0.5232292 ,\n",
       "          0.5315349 , 0.5074995 ],\n",
       "         [0.53732795, 0.55438805, 0.55287355, ..., 0.5378269 ,\n",
       "          0.5424136 , 0.5211717 ],\n",
       "         [0.52654684, 0.54308945, 0.5309398 , ..., 0.529505  ,\n",
       "          0.54362553, 0.5319546 ]],\n",
       " \n",
       "        [[0.509228  , 0.5500746 , 0.54352856, ..., 0.52138937,\n",
       "          0.538056  , 0.5314972 ],\n",
       "         [0.5455955 , 0.57755303, 0.57534873, ..., 0.53969884,\n",
       "          0.54535633, 0.5198106 ],\n",
       "         [0.5699887 , 0.60114735, 0.5928446 , ..., 0.5512787 ,\n",
       "          0.5625142 , 0.53090245],\n",
       "         ...,\n",
       "         [0.55902797, 0.56063837, 0.5631281 , ..., 0.55557173,\n",
       "          0.5524018 , 0.51520133],\n",
       "         [0.55283946, 0.5673547 , 0.56414574, ..., 0.54336154,\n",
       "          0.54884416, 0.5209335 ],\n",
       "         [0.5272878 , 0.56167686, 0.5481117 , ..., 0.5188189 ,\n",
       "          0.5278006 , 0.5163614 ]],\n",
       " \n",
       "        [[0.5170074 , 0.5687105 , 0.545059  , ..., 0.5153993 ,\n",
       "          0.542966  , 0.5396445 ],\n",
       "         [0.5467253 , 0.5835646 , 0.57096446, ..., 0.5459949 ,\n",
       "          0.53482157, 0.51821476],\n",
       "         [0.5936487 , 0.6152828 , 0.59171987, ..., 0.5581232 ,\n",
       "          0.5636054 , 0.5351413 ],\n",
       "         ...,\n",
       "         [0.52870685, 0.5133495 , 0.49680513, ..., 0.5377284 ,\n",
       "          0.53546035, 0.5008318 ],\n",
       "         [0.5286294 , 0.5250818 , 0.5079315 , ..., 0.5379168 ,\n",
       "          0.54209846, 0.50939757],\n",
       "         [0.5218327 , 0.5320166 , 0.5125372 , ..., 0.5260832 ,\n",
       "          0.5358648 , 0.52187335]]], dtype=float32)>}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_oct10(beethoven_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "79ce12f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'onset': <tf.Tensor: shape=(4, 172, 88), dtype=float32, numpy=\n",
       " array([[[1.00330047e-01, 2.60852836e-02, 4.11974033e-03, ...,\n",
       "          8.04347664e-08, 6.40524007e-08, 2.37228755e-06],\n",
       "         [5.50187081e-02, 2.11416800e-02, 2.51630717e-03, ...,\n",
       "          2.12454339e-08, 1.33039570e-08, 6.67369648e-07],\n",
       "         [6.93362579e-02, 4.17249352e-02, 4.47468646e-03, ...,\n",
       "          6.84766576e-07, 2.89789057e-07, 6.46032640e-06],\n",
       "         ...,\n",
       "         [2.45004721e-05, 4.04264085e-07, 1.29416051e-07, ...,\n",
       "          2.78809806e-04, 1.69223305e-04, 2.47982563e-03],\n",
       "         [1.16946478e-06, 7.29757310e-10, 5.56043322e-10, ...,\n",
       "          3.55879217e-03, 2.22265581e-03, 1.67798400e-02],\n",
       "         [1.05555613e-04, 4.12707948e-07, 4.06309880e-07, ...,\n",
       "          7.28279427e-02, 5.56767881e-02, 1.33258268e-01]],\n",
       " \n",
       "        [[6.09828979e-02, 4.50251818e-01, 1.75188005e-01, ...,\n",
       "          2.27900614e-06, 1.09542816e-06, 3.90493478e-05],\n",
       "         [6.69300649e-03, 2.59133764e-02, 1.74868573e-02, ...,\n",
       "          1.34002661e-07, 4.65961350e-08, 3.24472626e-06],\n",
       "         [1.47554046e-03, 1.75446668e-03, 2.28894316e-03, ...,\n",
       "          1.38345683e-06, 4.87051352e-07, 9.44703334e-06],\n",
       "         ...,\n",
       "         [2.04012231e-05, 2.59695611e-07, 9.08399400e-08, ...,\n",
       "          2.11401653e-04, 1.08251188e-04, 8.02022521e-04],\n",
       "         [1.11744680e-06, 4.07753831e-10, 2.85297258e-10, ...,\n",
       "          3.72124184e-03, 3.13517568e-03, 9.57619958e-03],\n",
       "         [1.12378890e-04, 2.81021613e-07, 2.00893581e-07, ...,\n",
       "          6.80767149e-02, 6.23122975e-02, 1.10203184e-01]],\n",
       " \n",
       "        [[4.67228889e-02, 2.51141191e-01, 5.25282621e-02, ...,\n",
       "          2.18548539e-05, 5.60911440e-06, 2.95435384e-05],\n",
       "         [4.14387602e-03, 7.10147293e-03, 2.19174754e-03, ...,\n",
       "          3.18220123e-06, 6.05734215e-07, 3.38612676e-06],\n",
       "         [7.87360535e-04, 4.26586106e-04, 1.47845800e-04, ...,\n",
       "          1.12674807e-05, 1.72297939e-06, 7.36831862e-06],\n",
       "         ...,\n",
       "         [2.83692102e-03, 1.30546920e-04, 1.20963436e-04, ...,\n",
       "          1.74075085e-05, 9.47157059e-06, 1.32756788e-04],\n",
       "         [1.27498317e-03, 1.86477464e-05, 2.69317261e-05, ...,\n",
       "          3.54728254e-04, 2.94758676e-04, 2.45493185e-03],\n",
       "         [1.35228131e-02, 7.92243576e-04, 1.00490649e-03, ...,\n",
       "          2.03371458e-02, 1.77327376e-02, 5.65146282e-02]],\n",
       " \n",
       "        [[6.01560213e-02, 4.10343289e-01, 3.78035486e-01, ...,\n",
       "          1.46463793e-03, 1.01553887e-04, 5.82337496e-04],\n",
       "         [1.20193092e-02, 5.53217418e-02, 4.94196266e-02, ...,\n",
       "          1.92502819e-04, 1.17533518e-05, 1.09373643e-04],\n",
       "         [4.57082829e-03, 1.11746537e-02, 6.76178839e-03, ...,\n",
       "          1.30731525e-04, 2.48841061e-05, 2.45189643e-04],\n",
       "         ...,\n",
       "         [5.37794977e-02, 4.55536135e-03, 6.48828503e-03, ...,\n",
       "          1.74126235e-05, 9.48042634e-06, 1.32951784e-04],\n",
       "         [1.28118113e-01, 8.36397558e-02, 5.16357869e-02, ...,\n",
       "          3.55087075e-04, 2.95281265e-04, 2.45957216e-03],\n",
       "         [2.83867210e-01, 2.76032150e-01, 2.14491323e-01, ...,\n",
       "          2.03553960e-02, 1.77589357e-02, 5.65886013e-02]]], dtype=float32)>,\n",
       " 'contour': <tf.Tensor: shape=(4, 172, 264), dtype=float32, numpy=\n",
       " array([[[0.72162867, 0.7340646 , 0.7071873 , ..., 0.86863   ,\n",
       "          0.7983953 , 0.73456985],\n",
       "         [0.7186808 , 0.7112084 , 0.6581775 , ..., 0.940816  ,\n",
       "          0.8977662 , 0.81088555],\n",
       "         [0.63268024, 0.58913976, 0.511185  , ..., 0.9668346 ,\n",
       "          0.938431  , 0.8898829 ],\n",
       "         ...,\n",
       "         [0.87869817, 0.85293305, 0.8619431 , ..., 0.8313008 ,\n",
       "          0.7966994 , 0.7515008 ],\n",
       "         [0.8968192 , 0.9020961 , 0.9072829 , ..., 0.7781439 ,\n",
       "          0.7432109 , 0.6917967 ],\n",
       "         [0.85197794, 0.8774574 , 0.90880954, ..., 0.7051758 ,\n",
       "          0.67715067, 0.64171463]],\n",
       " \n",
       "        [[0.54783314, 0.44935316, 0.37741372, ..., 0.75320315,\n",
       "          0.69322044, 0.63239133],\n",
       "         [0.6928609 , 0.64374626, 0.61313844, ..., 0.8348063 ,\n",
       "          0.7834726 , 0.7037643 ],\n",
       "         [0.8267678 , 0.8127678 , 0.84299356, ..., 0.89235914,\n",
       "          0.8514399 , 0.7812041 ],\n",
       "         ...,\n",
       "         [0.9050854 , 0.8777309 , 0.8663135 , ..., 0.87305015,\n",
       "          0.82318944, 0.76321596],\n",
       "         [0.9182304 , 0.92091763, 0.9174771 , ..., 0.8198733 ,\n",
       "          0.7729755 , 0.71296185],\n",
       "         [0.87651485, 0.8977274 , 0.923015  , ..., 0.740293  ,\n",
       "          0.7046069 , 0.6644525 ]],\n",
       " \n",
       "        [[0.533426  , 0.45497003, 0.4161161 , ..., 0.7710048 ,\n",
       "          0.7235446 , 0.6688341 ],\n",
       "         [0.70164007, 0.67891616, 0.6802256 , ..., 0.8550625 ,\n",
       "          0.8134697 , 0.73044145],\n",
       "         [0.8499901 , 0.8439512 , 0.8891765 , ..., 0.8998402 ,\n",
       "          0.8657075 , 0.8025873 ],\n",
       "         ...,\n",
       "         [0.83625907, 0.8165488 , 0.7644299 , ..., 0.9605234 ,\n",
       "          0.92635566, 0.880092  ],\n",
       "         [0.7909509 , 0.79052615, 0.75138795, ..., 0.9352049 ,\n",
       "          0.8980382 , 0.84007514],\n",
       "         [0.7156051 , 0.73228776, 0.7224354 , ..., 0.8848539 ,\n",
       "          0.8456673 , 0.7898561 ]],\n",
       " \n",
       "        [[0.54805773, 0.46368608, 0.35932013, ..., 0.6913386 ,\n",
       "          0.6303993 , 0.57350916],\n",
       "         [0.6707289 , 0.61568886, 0.5303142 , ..., 0.76772785,\n",
       "          0.7040025 , 0.61480564],\n",
       "         [0.79444695, 0.75954807, 0.7446916 , ..., 0.8274687 ,\n",
       "          0.7691178 , 0.6871135 ],\n",
       "         ...,\n",
       "         [0.6685967 , 0.8189265 , 0.90136826, ..., 0.9605234 ,\n",
       "          0.92635566, 0.880092  ],\n",
       "         [0.48079363, 0.49816826, 0.5670856 , ..., 0.9352049 ,\n",
       "          0.8980382 , 0.84007514],\n",
       "         [0.38036698, 0.3331073 , 0.28941342, ..., 0.8848539 ,\n",
       "          0.8456673 , 0.7898561 ]]], dtype=float32)>,\n",
       " 'note': <tf.Tensor: shape=(4, 172, 88), dtype=float32, numpy=\n",
       " array([[[5.59814125e-02, 2.41805962e-03, 7.79651338e-04, ...,\n",
       "          4.19451506e-04, 2.13649677e-04, 2.97972653e-03],\n",
       "         [2.22667903e-02, 5.97311999e-04, 1.42982957e-04, ...,\n",
       "          1.24484341e-05, 9.67392953e-06, 3.57687211e-04],\n",
       "         [1.79877002e-02, 6.09261682e-04, 1.72384738e-04, ...,\n",
       "          1.44338821e-06, 1.72216630e-06, 1.13298855e-04],\n",
       "         ...,\n",
       "         [9.19600856e-03, 1.06101530e-03, 6.20743260e-04, ...,\n",
       "          2.07389263e-03, 6.72440650e-03, 3.90226431e-02],\n",
       "         [6.82079121e-02, 3.44448313e-02, 2.60683559e-02, ...,\n",
       "          5.57235330e-02, 1.32933661e-01, 2.47931197e-01],\n",
       "         [3.06184858e-01, 3.74718159e-01, 3.58054787e-01, ...,\n",
       "          4.34719890e-01, 5.96629858e-01, 5.90050638e-01]],\n",
       " \n",
       "        [[2.20502168e-02, 4.48120991e-04, 1.43202511e-03, ...,\n",
       "          1.17719034e-03, 4.71146574e-04, 4.73497342e-03],\n",
       "         [3.15844407e-03, 1.83539178e-05, 4.16209841e-05, ...,\n",
       "          4.51259839e-05, 2.88129831e-05, 6.70262671e-04],\n",
       "         [6.64982654e-04, 1.95383291e-06, 2.93866924e-06, ...,\n",
       "          5.47935770e-06, 5.92842753e-06, 2.34713400e-04],\n",
       "         ...,\n",
       "         [7.95716792e-03, 8.67897063e-04, 5.07949502e-04, ...,\n",
       "          1.56877295e-03, 5.47859119e-03, 3.41259353e-02],\n",
       "         [6.14299066e-02, 2.94072218e-02, 2.16830261e-02, ...,\n",
       "          5.21454290e-02, 1.29447892e-01, 2.42585421e-01],\n",
       "         [2.92984366e-01, 3.52667868e-01, 3.28578830e-01, ...,\n",
       "          4.49340373e-01, 6.14688694e-01, 5.99997461e-01]],\n",
       " \n",
       "        [[1.87580697e-02, 3.39867547e-04, 1.07989844e-03, ...,\n",
       "          1.06284686e-03, 4.50305088e-04, 4.61413153e-03],\n",
       "         [2.48942687e-03, 1.36234312e-05, 2.99479598e-05, ...,\n",
       "          3.97056683e-05, 2.60515171e-05, 6.66573062e-04],\n",
       "         [5.31504862e-04, 1.56870271e-06, 2.22481231e-06, ...,\n",
       "          4.70605073e-06, 4.97166411e-06, 2.33283296e-04],\n",
       "         ...,\n",
       "         [2.19499897e-02, 4.69455821e-03, 3.75421718e-03, ...,\n",
       "          5.05576085e-04, 1.89452106e-03, 1.80828013e-02],\n",
       "         [1.24191441e-01, 9.04371366e-02, 9.27637741e-02, ...,\n",
       "          2.76803765e-02, 7.64572099e-02, 1.86025485e-01],\n",
       "         [3.85674655e-01, 4.89273489e-01, 5.24341941e-01, ...,\n",
       "          3.92994493e-01, 5.73695421e-01, 5.81952810e-01]],\n",
       " \n",
       "        [[3.41501869e-02, 1.33822020e-03, 4.72077215e-03, ...,\n",
       "          2.68371170e-03, 7.47681246e-04, 7.02844560e-03],\n",
       "         [6.91132527e-03, 7.91338898e-05, 1.82554679e-04, ...,\n",
       "          1.35880124e-04, 5.70940356e-05, 1.16515427e-03],\n",
       "         [1.79066288e-03, 9.29855923e-06, 1.17075097e-05, ...,\n",
       "          1.76999893e-05, 1.24219532e-05, 4.29987558e-04],\n",
       "         ...,\n",
       "         [6.78787529e-02, 3.98347713e-02, 2.08110139e-02, ...,\n",
       "          5.91798336e-04, 2.25315266e-03, 2.00124886e-02],\n",
       "         [3.40709746e-01, 4.63577718e-01, 3.84837002e-01, ...,\n",
       "          2.94024050e-02, 8.16422477e-02, 1.92495987e-01],\n",
       "         [6.19355857e-01, 8.04011226e-01, 7.92334735e-01, ...,\n",
       "          3.97234797e-01, 5.78705847e-01, 5.84792733e-01]]], dtype=float32)>}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nov06(beethoven_x[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
